–ü–µ—Ä–µ–π—Ç–∏ –∫ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É

–í—ã —Å–∫–∞–∑–∞–ª–∏:
Programming Assignment 4:
Clustering Analysis
Shen-Shyang Ho (Dr.)
November 19, 2025
‚Ä¢ In this assignment, you will use the dataset you have used in your previous assignments.
‚Ä¢ We will use the features extracted from the last convolution layer of a ‚ÄùResNet18‚Äù deep learning
architecture as image representation for this clustering assignment using ‚Äúforward hook‚Äù in PyTorch
(https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_
module_forward_hook.html) OR ‚Äúfeature extraction‚Äù in TorchVision (https://pytorch.org/
vision/stable/feature_extraction.html). You can also use other approaches that are found
on the internet.
‚Ä¢ The labels in your dataset will be used as ground truths for performance evaluation when we use
external performance measure.
‚Ä¢ You will use the following clustering methods: K-means, Spectral Clustering, Hierarchical
Clustering, DBSCAN, Bisecting K-means
‚Ä¢ Scikit-learn (https://scikit-learn.org/stable/user_guide.html) will be used in this
assignment.
‚Ä¢ In particular, most important coding information should be available in https://scikit-learn.
org/stable/modules/clustering.html
1. (Feature Extraction)
‚Ä¢ You are recommended to resize images to a fixed dimension (say, 224 √ó 224 pixel) before the
feature extraction.
‚Ä¢ Normalize the resized image dataset.
‚Ä¢ Extract features for each image from the last convolution layer of ‚ÄúResNet18‚Äù (You can follow
https://kozodoi.me/blog/20210527/extracting-features. But you must reference
this website in your solution) (2.5 points)
2. (Dimension Reduction) Perform dimension reduction on your new dog image representation dataset
to reduce the dimension to 2 (similar to Assignment 1). (0.5 points)
3. (Clustering Algorithm) Perform clustering using the following approaches on the 2D dataset you
preprocessed in Item 2:
‚Ä¢ K-mean clustering and its variants for ùêæ = 4:
(a) K-means clustering: (Use KMeans with init = ‚ÄòRandom‚Äô) (0.5 point)
(b) KMeans with init=‚Äòk-means++‚Äô (0.5 point)
1
(c) Bisecting K-means (sklearn.cluster.BisectingKMeans with init = ‚ÄòRandom‚Äô) (0.5 point)
(d) spectral clustering (sklearn.cluster.SpectralClustering with default parameters) (0.5 point)
‚Ä¢ DBSCAN (0.5 point)
‚Äì What are the eps and min samples parameter values you used to get 4 clusters? (0.5
point)
‚Ä¢ Agglomerative clustering (i.e., hierarchical clustering) - use sklearn.cluster.AgglomerativeClustering
with number of clusters set to 4
(a) Single link (MIN), (0.5 point)
(b) Complete link (MAX), (0.5 point)
(c) Group Average, and (0.5 point)
(d) Ward‚Äôs method (0.5 point)
Use the four linkage values ‚Äòward‚Äô, ‚Äòcomplete‚Äô, ‚Äòaverage‚Äô, ‚Äòsingle‚Äô for sklearn.cluster.
AgglomerativeClustering
4. (Clustering Evaluations) For all the methods in Item 3:
(a) Perform clustering performance evaluation using Fowlkes-Mallows index (sklearn.metrics.fowlkes
mallows score). Compute the Fowlkes-Mallows index for each method on the 2D dataset. (0.5
point)
(b) Perform clustering performance evaluation using Silhouette Coefficient (sklearn.metrics.silhouette score).
Compute the Silhouette Coefficient for each method. (0.5 point)
(c) Rank the methods from the best to the worst for your dataset based on Fowlkes-Mallows index.
(0.5 point)
(d) Rank the methods from the best to the worst for your dataset based on Silhouette Coefficient.
(0.5 point)
ChatGPT —Å–∫–∞–∑–∞–ª:

–î—É–º–∞–ª –Ω–∞ –ø—Ä–æ—Ç—è–∂–µ–Ω–∏–∏ 6s
–ù–∏–∂–µ ‚Äî –≥–æ—Ç–æ–≤—ã–π —Å–∫–µ–ª–µ—Ç —Ä–µ—à–µ–Ω–∏—è (Python) –ø–æ–¥ —Ç–≤–æ–π Programming Assignment 4. –û–Ω –¥–µ–ª–∞–µ—Ç —Ä–æ–≤–Ω–æ —Ç–æ, —á—Ç–æ –ø—Ä–æ—Å–∏—Ç Dr. Ho: ResNet18 last conv features ‚Üí reduce to 2D ‚Üí –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è 9 –º–µ—Ç–æ–¥–∞–º–∏ ‚Üí FMI + Silhouette ‚Üí —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ.

–Ø —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –æ—Å—Ç–∞–≤–∏–ª –º–µ—Å—Ç–∞, –≥–¥–µ —Ç—ã –≤—Å—Ç–∞–≤–∏—à—å –ø—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É –∏ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ) –≤—ã–±–µ—Ä–µ—à—å PCA/TSNE.

0) –£—Å—Ç–∞–Ω–æ–≤–∫–∞/–∏–º–ø–æ—Ä—Ç—ã
import os
import numpy as np
import pandas as pd

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models

from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler

from sklearn.cluster import (
    KMeans, BisectingKMeans, SpectralClustering, DBSCAN, AgglomerativeClustering
)
from sklearn.metrics import fowlkes_mallows_score, silhouette_score
1) Feature Extraction (ResNet18 last conv layer)
–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ: resize 224√ó224, normalize, –∏ features –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ conv —Å–ª–æ—è ResNet18.

–í–∞–∂–Ω–æ: –≤ –æ—Ç—á—ë—Ç–µ —É–ø–æ–º—è–Ω–∏ —Å—Å—ã–ª–∫—É, –∫–æ—Ç–æ—Ä—É—é —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–æ—Ñ–µ—Å—Å–æ—Ä:
https://kozodoi.me/blog/20210527/extracting-features (–∫–∞–∫ reference).

–í–∞—Ä–∏–∞–Ω—Ç A (—Ä–µ–∫–æ–º–µ–Ω–¥—É—é): TorchVision feature_extraction
from torchvision.models.feature_extraction import create_feature_extractor

# 1) Dataset path (ImageFolder –æ–∂–∏–¥–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É: root/class_name/*.jpg)
DATA_DIR = "/path/to/your/dog_dataset"  # <-- –ø–æ–º–µ–Ω—è–π

# 2) Preprocess: resize + normalize (ImageNet stats)
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

dataset = datasets.ImageFolder(DATA_DIR, transform=transform)
loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=2)

y_true = np.array([label for _, label in dataset.samples])  # ground truth labels

# 3) ResNet18
weights = models.ResNet18_Weights.DEFAULT
resnet = models.resnet18(weights=weights)
resnet.eval()

# 4) Extract from "layer4" (last conv block output)
# return_nodes: map internal node name -> output name you choose
extractor = create_feature_extractor(resnet, return_nodes={"layer4": "feat"})
–¢–µ–ø–µ—Ä—å –ø–æ–ª—É—á–∞–µ–º embedding: layer4 –∏–º–µ–µ—Ç —Ñ–æ—Ä–º—É [B, 512, 7, 7]. –ß—Ç–æ–±—ã –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å –≤ –≤–µ–∫—Ç–æ—Ä –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ ‚Äî –¥–µ–ª–∞–µ–º Global Average Pooling ‚Üí [B, 512].

@torch.no_grad()
def extract_features(dataloader, extractor, device="cpu"):
    extractor.to(device)
    feats_list = []
    for x, _ in dataloader:
        x = x.to(device)
        out = extractor(x)["feat"]              # [B, 512, 7, 7]
        out = out.mean(dim=(2, 3))              # GAP -> [B, 512]
        feats_list.append(out.cpu().numpy())
    return np.vstack(feats_list)

device = "cuda" if torch.cuda.is_available() else "cpu"
X = extract_features(loader, extractor, device=device)  # shape [N, 512]
print("Feature matrix:", X.shape)
2) Dimension Reduction –¥–æ 2D
–ü—Ä–æ—Ñ–µ—Å—Å–æ—Ä –ø—Ä–æ—Å–∏—Ç ‚Äúsimilar to Assignment 1‚Äù. –ï—Å–ª–∏ –≤ Assignment 1 —É —Ç–µ–±—è –±—ã–ª PCA, –±–µ—Ä–∏ PCA. –ï—Å–ª–∏ –±—ã–ª t-SNE, –±–µ—Ä–∏ t-SNE. –Ø –¥–∞–º –æ–±–∞; –≤—ã–±–µ—Ä–∏ –æ–¥–∏–Ω.

–ü–µ—Ä–µ–¥ —Å–Ω–∏–∂–µ–Ω–∏–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –æ–±—ã—á–Ω–æ –Ω–æ—Ä–º –¥–µ–ª–∞—é—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—é:

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
PCA ‚Üí 2D (–±—ã—Å—Ç—Ä–æ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ)
X_2d = PCA(n_components=2, random_state=42).fit_transform(X_scaled)
–∏–ª–∏ t-SNE ‚Üí 2D (–º–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ –∫—Ä–∞—Å–∏–≤–æ)
X_2d = TSNE(n_components=2, random_state=42, perplexity=30, learning_rate="auto",
            init="pca").fit_transform(X_scaled)
3) Clustering –Ω–∞ 2D (–≤—Å–µ –º–µ—Ç–æ–¥—ã –∏–∑ –∑–∞–¥–∞–Ω–∏—è)
–°–æ–±–µ—Ä—ë–º —Ñ—É–Ω–∫—Ü–∏–∏, —á—Ç–æ–±—ã –æ–¥–∏–Ω–∞–∫–æ–≤–æ —Å—á–∏—Ç–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏.

def eval_clustering(name, y_pred, X_2d, y_true):
    # Fowlkes-Mallows uses ground truth + predicted labels
    fmi = fowlkes_mallows_score(y_true, y_pred)

    # Silhouette needs at least 2 clusters; also fails if a cluster has 1 point sometimes
    # We'll guard with try/except
    try:
        sil = silhouette_score(X_2d, y_pred)
    except Exception:
        sil = np.nan

    return {"method": name, "FMI": fmi, "Silhouette": sil, "n_clusters": len(set(y_pred))}
KMeans (Random init) –∏ KMeans++ (K=4)
results = []

km_random = KMeans(n_clusters=4, init="random", n_init=10, random_state=42)
y_km_random = km_random.fit_predict(X_2d)
results.append(eval_clustering("KMeans (init=random)", y_km_random, X_2d, y_true))

km_pp = KMeans(n_clusters=4, init="k-means++", n_init=10, random_state=42)
y_km_pp = km_pp.fit_predict(X_2d)
results.append(eval_clustering("KMeans (init=k-means++)", y_km_pp, X_2d, y_true))
Bisecting K-Means (init=random, K=4)
bkm = BisectingKMeans(n_clusters=4, init="random", random_state=42)
y_bkm = bkm.fit_predict(X_2d)
results.append(eval_clustering("BisectingKMeans (init=random)", y_bkm, X_2d, y_true))
Spectral Clustering (default params, K=4)
sc = SpectralClustering(n_clusters=4, random_state=42)
y_sc = sc.fit_predict(X_2d)
results.append(eval_clustering("SpectralClustering (default)", y_sc, X_2d, y_true))
DBSCAN + –ø–æ–¥–±–æ—Ä eps/min_samples —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å 4 –∫–ª–∞—Å—Ç–µ—Ä–∞
DBSCAN –º–æ–∂–µ—Ç –¥–∞–≤–∞—Ç—å -1 –∫–∞–∫ noise. –í –∑–∞–¥–∞–Ω–∏–∏ –ø—Ä–æ—Å—è—Ç: –∫–∞–∫–∏–µ eps –∏ min_samples —Ç—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å 4 clusters.

def dbscan_find_params(X_2d, target_k=4):
    # —Ä–∞–∑—É–º–Ω—ã–µ —Å–µ—Ç–∫–∏; –º–æ–∂–µ—à—å —Ä–∞—Å—à–∏—Ä–∏—Ç—å
    eps_grid = np.linspace(0.1, 5.0, 50)
    min_samples_grid = [3, 4, 5, 6, 8, 10]

    best = None
    for ms in min_samples_grid:
        for eps in eps_grid:
            model = DBSCAN(eps=float(eps), min_samples=int(ms))
            labels = model.fit_predict(X_2d)
            # —á–∏—Å–ª–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –±–µ–∑ noise (-1)
            clusters = set(labels)
            k = len([c for c in clusters if c != -1])
            if k == target_k:
                # –º–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å "–ª—É—á—à–∏–π" –ø–æ silhouette —Å—Ä–µ–¥–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö
                try:
                    sil = silhouette_score(X_2d, labels)
                except Exception:
                    sil = -np.inf
                cand = (sil, eps, ms, labels)
                if (best is None) or (cand[0] > best[0]):
                    best = cand

    return best  # (sil, eps, ms, labels) –∏–ª–∏ None

best_db = dbscan_find_params(X_2d, target_k=4)
if best_db is None:
    print("DBSCAN: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–æ–≤–Ω–æ 4 –∫–ª–∞—Å—Ç–µ—Ä–∞ –Ω–∞ —Ç–µ–∫—É—â–µ–π —Å–µ—Ç–∫–µ. –†–∞—Å—à–∏—Ä—å eps_grid/min_samples.")
else:
    sil, eps_used, ms_used, y_db = best_db
    print("DBSCAN params -> eps:", eps_used, "min_samples:", ms_used)
    results.append(eval_clustering(f"DBSCAN (eps={eps_used:.3f}, min_samples={ms_used})", y_db, X_2d, y_true))
Agglomerative (Hierarchical) Clustering, K=4: single/complete/average/ward
for linkage in ["single", "complete", "average", "ward"]:
    agg = AgglomerativeClustering(n_clusters=4, linkage=linkage)
    y_agg = agg.fit_predict(X_2d)
    results.append(eval_clustering(f"Agglomerative (linkage={linkage})", y_agg, X_2d, y_true))
4) Evaluation + Ranking (FMI –∏ Silhouette)
df = pd.DataFrame(results)

# –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ (best -> worst)
df_fmi_ranked = df.sort_values(by="FMI", ascending=False).reset_index(drop=True)
df_sil_ranked = df.sort_values(by="Silhouette", ascending=False).reset_index(drop=True)

print("\n=== Results (all) ===")
print(df)

print("\n=== Rank by FMI (best -> worst) ===")
print(df_fmi_ranked[["method", "FMI", "Silhouette", "n_clusters"]])

print("\n=== Rank by Silhouette (best -> worst) ===")
print(df_sil_ranked[["method", "Silhouette", "FMI", "n_clusters"]])
–ß—Ç–æ –Ω–∞–ø–∏—Å–∞—Ç—å –≤ –æ—Ç—á—ë—Ç–µ (–∫–æ—Ä–æ—Ç–∫–æ –ø–æ –ø—É–Ω–∫—Ç–∞–º –∑–∞–¥–∞–Ω–∏—è)
Feature extraction:

images resized to 224√ó224

normalized with ImageNet mean/std

ResNet18 pretrained, extracted from last convolution block (layer4)

global average pooling ‚Üí 512-d vector

reference: kozodoi link (–æ–±—è–∑–∞—Ç–µ–ª–µ–Ω)

Dim reduction:

StandardScaler

PCA to 2D (–∏–ª–∏ t-SNE –µ—Å–ª–∏ —Ç–∞–∫ –±—ã–ª–æ –≤ Assignment 1)

Clustering:

KMeans init=random (K=4)

KMeans++ (K=4)

BisectingKMeans init=random (K=4)

SpectralClustering default (K=4)

DBSCAN: –≤—Å—Ç–∞–≤—å eps –∏ min_samples, –∫–æ—Ç–æ—Ä—ã–µ –∫–æ–¥ –Ω–∞—à—ë–ª

Agglomerative: linkage single/complete/average/ward (K=4)

Evaluations:

FMI –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–µ—Ç–æ–¥–∞

Silhouette –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–µ—Ç–æ–¥–∞

2 —Ç–∞–±–ª–∏—Ü—ã —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è: –ø–æ FMI –∏ –ø–æ Silhouette

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, —Å–∫–∏–Ω—å:

–ø—É—Ç—å/—Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–≤–æ–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ (–∏–ª–∏ –ø—Ä–æ—Å—Ç–æ ‚Äú–∫–∞–∫ –ª–µ–∂–∞—Ç –ø–∞–ø–∫–∏‚Äù),

–∏ —á—Ç–æ –∏–º–µ–Ω–Ω–æ —Ç—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª –≤ Assignment 1 (PCA –∏–ª–∏ t-SNE),

–∏ —è –ø–æ–¥—Å—Ç—Ä–æ—é –∫–æ–¥ 1:1 –ø–æ–¥ —Ç–≤–æ–π –ø—Ä–æ–µ–∫—Ç (–≤–∫–ª—é—á–∞—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ç–∞–±–ª–∏—Ü—É/CSV –∏ –∫—Ä–∞—Å–∏–≤—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ 2D —Å —Ü–≤–µ—Ç–∞–º–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤).

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–∞ –∫–∞–∫–æ–π –¥–∞—Ç–∞—Å–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å?
ChatGPT —Å–∫–∞–∑–∞–ª:
–ö–æ—Ä–æ—Ç–∫–æ –∏ –ø–æ-–ø—Ä–æ—Ñ–µ—Å—Å–æ—Ä—Å–∫–∏ üëá

–ö–∞–∫–æ–π –¥–∞—Ç–∞—Å–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
–ò—Å–ø–æ–ª—å–∑—É–π –¢–û–¢ –ñ–ï –°–ê–ú–´–ô –¥–∞—Ç–∞—Å–µ—Ç, –∫–æ—Ç–æ—Ä—ã–π —Ç—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª –≤ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∑–∞–¥–∞–Ω–∏—è—Ö (Assignment 1‚Äì3).

–≠—Ç–æ –ø—Ä—è–º–æ —Å–ª–µ–¥—É–µ—Ç –∏–∑ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏ –∑–∞–¥–∞–Ω–∏—è:

‚ÄúIn this assignment, you will use the dataset you have used in your previous assignments.‚Äù

–ï—Å–ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –ø–æ —Ç–≤–æ–µ–º—É –∫—É—Ä—Å—É (Data Mining / Image assignments)
–í –∑–∞–¥–∞–Ω–∏–∏ –¥–∞–ª—å—à–µ –ø—Ä—è–º–æ –Ω–∞–ø–∏—Å–∞–Ω–æ:

‚ÄúPerform dimension reduction on your new dog image representation dataset ‚Ä¶‚Äù

üëâ –ó–Ω–∞—á–∏—Ç:

—ç—Ç–æ –¥–∞—Ç–∞—Å–µ—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ —Å–æ–±–∞–∫

—Ç–æ—Ç –∂–µ —Å–∞–º—ã–π, —á—Ç–æ —Ç—ã —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª —Ä–∞–Ω–µ–µ

—Å label‚Äô–∞–º–∏ –∫–ª–∞—Å—Å–æ–≤ —Å–æ–±–∞–∫, –∫–æ—Ç–æ—Ä—ã–µ —Ç–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¢–û–õ–¨–ö–û –¥–ª—è –æ—Ü–µ–Ω–∫–∏ (FMI)

–¢–∏–ø–∏—á–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ (–∫–∞–∫ –æ–∂–∏–¥–∞–µ—Ç ImageFolder)
dog_dataset/
‚îú‚îÄ‚îÄ class_0/
‚îÇ   ‚îú‚îÄ‚îÄ img1.jpg
‚îÇ   ‚îú‚îÄ‚îÄ img2.jpg
‚îú‚îÄ‚îÄ class_1/
‚îÇ   ‚îú‚îÄ‚îÄ img3.jpg
‚îÇ   ‚îú‚îÄ‚îÄ img4.jpg
‚îú‚îÄ‚îÄ class_2/
‚îú‚îÄ‚îÄ class_3/
–ü–∞–ø–∫–∏ = ground truth labels

–í –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ —Ç—ã –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ—à—å labels

Labels –Ω—É–∂–Ω—ã —Ç–æ–ª—å–∫–æ –¥–ª—è Fowlkes‚ÄìMallows index

–ï—Å–ª–∏ –≤–¥—Ä—É–≥ —É —Ç–µ–±—è –±—ã–ª –≤—ã–±–æ—Ä —Ä–∞–Ω–µ–µ
–ï—Å–ª–∏ –≤ –ø—Ä–æ—à–ª—ã—Ö –∑–∞–¥–∞–Ω–∏—è—Ö —Ç—ã –≤—ã–±–∏—Ä–∞–ª –º–µ–∂–¥—É –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏:

–í–∞—Ä–∏–∞–Ω—Ç	–ú–æ–∂–Ω–æ?	–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π
–¢–æ—Ç –∂–µ dog dataset	‚úÖ –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ	–°–∞–º—ã–π –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
–î—Ä—É–≥–æ–π image dataset	‚ùå	–ü—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—Ç –∑–∞–¥–∞–Ω–∏—é
CIFAR / ImageNet subset	‚ùå	–ï—Å–ª–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª —Ä–∞–Ω—å—à–µ
–ù–æ–≤—ã–π Kaggle dataset	‚ùå	–ú–æ–≥—É—Ç —Å–Ω—è—Ç—å –±–∞–ª–ª—ã
–ß—Ç–æ –Ω–∞–ø–∏—Å–∞—Ç—å –≤ –æ—Ç—á—ë—Ç–µ (1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ)
‚ÄúIn this assignment, we used the same dog image dataset as in previous assignments to ensure consistency in feature representation and clustering evaluation.‚Äù

–ï—Å–ª–∏ —Å–æ–º–Ω–µ–≤–∞–µ—à—å—Å—è, —Å–∫–∞–∂–∏ –º–Ω–µ, —á—Ç–æ –∏–º–µ–Ω–Ω–æ —Ç—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª –≤ Assignment 1‚Äì3
(–Ω–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —Å–∫—Ä–∏–Ω/–æ–ø–∏—Å–∞–Ω–∏–µ), –∏ —è —Å–∫–∞–∂—É 100% –≤–µ—Ä–Ω–æ, –æ–∫ –ª–∏ —ç—Ç–æ –¥–ª—è Dr. Ho –∏ –∫–∞–∫ –ª—É—á—à–µ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤ –æ—Ç—á—ë—Ç–µ.

–í—ã —Å–∫–∞–∑–∞–ª–∏:
/content/drive/MyDrive/Faulty_solar_panel —Ç—É—Ç –º–æ–π —Ñ–∞–π–ª –Ω–∞—Ö–æ–¥–∏—Ç—Å—è 
ChatGPT —Å–∫–∞–∑–∞–ª:
–û–∫ ‚Äî –∑–Ω–∞—á–∏—Ç –∏—Å–ø–æ–ª—å–∑—É–π –∏–º–µ–Ω–Ω–æ —ç—Ç–æ—Ç –¥–∞—Ç–∞—Å–µ—Ç (Faulty_solar_panel), –ø–æ—Ç–æ–º—É —á—Ç–æ –≤ –∑–∞–¥–∞–Ω–∏–∏ –≥–ª–∞–≤–Ω–æ–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ: ‚Äúuse the dataset you have used in your previous assignments‚Äù. –¢–æ, —á—Ç–æ –≤ —Ç–µ–∫—Å—Ç–µ —É–ø–æ–º—è–Ω—É—Ç–æ ‚Äúdog image dataset‚Äù, —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –ø—Ä–æ—Å—Ç–æ –æ—Å—Ç–∞—Ç–æ–∫ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ ‚Äî —É —Ç–µ–±—è –±—É–¥–µ—Ç solar panel dataset, –∏ —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –æ–Ω –±—ã–ª –≤ –ø—Ä–æ—à–ª—ã—Ö –∑–∞–¥–∞–Ω–∏—è—Ö.

–ù–∏–∂–µ ‚Äî –∫–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —É–∫–∞–∑–∞—Ç—å –ø—É—Ç—å –∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –≤ Colab.

1) –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø–∞–ø–æ–∫
–í Colab –≤—ã–ø–æ–ª–Ω–∏:

import os

DATA_DIR = "/content/drive/MyDrive/Faulty_solar_panel"
print("Exists:", os.path.exists(DATA_DIR))
print("Top-level:", os.listdir(DATA_DIR)[:20])
–ò–¥–µ–∞–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è ImageFolder (—Å–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π –≤–∞—Ä–∏–∞–Ω—Ç)
–ß—Ç–æ–±—ã torchvision.datasets.ImageFolder —Ä–∞–±–æ—Ç–∞–ª ‚Äú–∏–∑ –∫–æ—Ä–æ–±–∫–∏‚Äù, –≤–Ω—É—Ç—Ä–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–∞–ø–∫–∏-–∫–ª–∞—Å—Å—ã:

Faulty_solar_panel/
‚îú‚îÄ‚îÄ classA/
‚îÇ   ‚îú‚îÄ‚îÄ img1.jpg
‚îÇ   ‚îú‚îÄ‚îÄ img2.jpg
‚îú‚îÄ‚îÄ classB/
‚îú‚îÄ‚îÄ classC/
‚îú‚îÄ‚îÄ classD/
–ï—Å–ª–∏ —É —Ç–µ–±—è —Ç–∞–∫ ‚Äî –ø—Ä–æ—Å—Ç–æ –¥–µ–ª–∞–π:

from torchvision import datasets, transforms

transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

dataset = datasets.ImageFolder(DATA_DIR, transform=transform)
print("Classes:", dataset.classes)
print("Num images:", len(dataset))
2) –ï—Å–ª–∏ —É —Ç–µ–±—è –∫–∞—Ä—Ç–∏–Ω–∫–∏ –ª–µ–∂–∞—Ç –ù–ï –ø–æ –ø–∞–ø–∫–∞–º, –∞ –µ—Å—Ç—å CSV —Å label‚Äô–∞–º–∏
–¢–æ–≥–¥–∞ ImageFolder –Ω–µ –ø–æ–¥–æ–π–¥–µ—Ç ‚Äî –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç —á–∏—Ç–∞—Ç—å CSV –∏ –¥–µ–ª–∞—Ç—å –∫–∞—Å—Ç–æ–º–Ω—ã–π Dataset.
–ù–æ –¥–ª—è –∑–∞–¥–∞–Ω–∏—è —ç—Ç–æ —Ç–æ–∂–µ –æ–∫, –≥–ª–∞–≤–Ω–æ–µ —á—Ç–æ–±—ã:

—Ç—ã –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª labels –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏,

labels –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª —Ç–æ–ª—å–∫–æ –¥–ª—è FMI (Fowlkes‚ÄìMallows).

3) –ß—Ç–æ –Ω–∞–ø–∏—Å–∞—Ç—å –≤ –æ—Ç—á—ë—Ç–µ (—á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –≤–æ–ø—Ä–æ—Å–æ–≤)
–û–¥–Ω–æ–π —Ñ—Ä–∞–∑–æ–π:

‚ÄúWe used the same Faulty_solar_panel image dataset as in previous assignments. The ground-truth labels were only used for external evaluation (Fowlkes‚ÄìMallows index), not for clustering.‚Äù

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, —è –º–æ–≥—É —Å—Ä–∞–∑—É –ø–æ–¥—Å—Ç—Ä–æ–∏—Ç—å –∫–æ–¥ 1:1 –ø–æ–¥ —Ç–≤–æ—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É: –ø—Ä–æ—Å—Ç–æ –ø—Ä–∏—à–ª–∏ –≤—ã–≤–æ–¥ os.listdir(DATA_DIR) (–ø–µ—Ä–≤—ã–µ 20 —ç–ª–µ–º–µ–Ω—Ç–æ–≤) –∏–ª–∏ —Å–∫–∞–∂–∏, –µ—Å—Ç—å –ª–∏ –≤–Ω—É—Ç—Ä–∏ CSV (–Ω–∞–ø—Ä–∏–º–µ—Ä labels.csv, train.csv –∏ —Ç.–ø.).

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
—ç—Ç–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –º–æ–∏—Ö —Ñ–∞–π–ª–æ–≤, —Ç—ã –ø–æ–º–Ω–∏—à—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –º–æ–∏—Ö —Ñ–∞–π–ª–æ–≤?
ChatGPT —Å–∫–∞–∑–∞–ª:
–î–∞ ‚Äî —Ç–µ–ø–µ—Ä—å —è —Ç–æ—á–Ω–æ –ø–æ–º–Ω—é –∏ –ø–æ–Ω–∏–º–∞—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–≤–æ–∏—Ö —Ñ–∞–π–ª–æ–≤ üëç
–ò –æ–Ω–∞ –∏–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è.

–¢–≤–æ—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (–∫–∞–∫ —è –µ—ë –≤–∏–∂—É)
Faulty_solar_panel/
‚îú‚îÄ‚îÄ Bird-drop/
‚îú‚îÄ‚îÄ Clean/
‚îú‚îÄ‚îÄ Dusty/
‚îú‚îÄ‚îÄ Snow-Covered/
‚îú‚îÄ‚îÄ train.json
‚îú‚îÄ‚îÄ test.json
‚îú‚îÄ‚îÄ validation.json
‚îú‚îÄ‚îÄ .DS_Store
‚îú‚îÄ‚îÄ venv/   (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
–ß—Ç–æ –∑–¥–µ—Å—å –≤–∞–∂–Ω–æ üëá
4 –ø–∞–ø–∫–∏ = 4 ground truth –∫–ª–∞—Å—Å–∞
‚Üí –∏–¥–µ–∞–ª—å–Ω–æ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ–º K = 4

–§–æ—Ä–º–∞—Ç ImageFolder-ready
‚Üí torchvision.datasets.ImageFolder –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Å—Ä–∞–∑—É

JSON-—Ñ–∞–π–ª—ã –º–æ–∂–Ω–æ –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è
(—Ç—ã –Ω–µ –æ–±—É—á–∞–µ—à—å –º–æ–¥–µ–ª—å, —Ç–æ–ª—å–∫–æ –∏–∑–≤–ª–µ–∫–∞–µ—à—å –ø—Ä–∏–∑–Ω–∞–∫–∏)

–ö–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç–æ—Ç –¥–∞—Ç–∞—Å–µ—Ç –≤ –∑–∞–¥–∞–Ω–∏–∏
1Ô∏è‚É£ –ß—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
–ò—Å–ø–æ–ª—å–∑—É–π –í–°–ï –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ 4 –ø–∞–ø–æ–∫:

Bird-drop

Clean

Dusty

Snow-Covered

‚ùå –ù–ï –¥–µ–ª–∏ –Ω–∞ train / test / val
–≠—Ç–æ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è, –∞ –Ω–µ supervised learning.

2Ô∏è‚É£ –ö–∞–∫ –∑–∞–≥—Ä—É–∂–∞—Ç—å (—Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç)
DATA_DIR = "/content/drive/MyDrive/Faulty_solar_panel"

from torchvision import datasets, transforms

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    ),
])

dataset = datasets.ImageFolder(DATA_DIR, transform=transform)

print("Classes:", dataset.classes)
print("Class to index:", dataset.class_to_idx)
print("Total images:", len(dataset))
–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥ –ø—Ä–∏–º–µ—Ä–Ω–æ —Ç–∞–∫–æ–π:

Classes: ['Bird-drop', 'Clean', 'Dusty', 'Snow-Covered']
Class to index: {'Bird-drop': 0, 'Clean': 1, 'Dusty': 2, 'Snow-Covered': 3}
3Ô∏è‚É£ –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å labels (–í–ê–ñ–ù–û)
‚ùå –ù–ï –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å labels –≤ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏

‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å labels –¢–û–õ–¨–ö–û –∑–¥–µ—Å—å:

from sklearn.metrics import fowlkes_mallows_score

fmi = fowlkes_mallows_score(y_true, y_pred)
–≠—Ç–æ —Ä–æ–≤–Ω–æ —Ç–æ, —á—Ç–æ —Ç—Ä–µ–±—É–µ—Ç Dr. Ho.

–ß—Ç–æ –Ω–∞–ø–∏—Å–∞—Ç—å –≤ –æ—Ç—á—ë—Ç–µ (—á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –≤–æ–ø—Ä–æ—Å–æ–≤)
–ú–æ–∂–µ—à—å –≤—Å—Ç–∞–≤–∏—Ç—å 1:1:

‚ÄúWe used the Faulty Solar Panel image dataset, which consists of four classes (Bird-drop, Clean, Dusty, and Snow-Covered). The dataset was previously used in earlier assignments. Ground-truth labels were only used for external clustering evaluation (Fowlkes‚ÄìMallows index), not for clustering.‚Äù

–ò—Ç–æ–≥ (–∫–æ—Ä–æ—Ç–∫–æ)
‚úÖ –î–∞—Ç–∞—Å–µ—Ç ‚Äî –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π
‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ ‚Äî –∏–¥–µ–∞–ª—å–Ω–∞—è
‚úÖ K = 4 ‚Äî –ª–æ–≥–∏—á–Ω–æ –∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ
‚úÖ Professor Ho ‚Äî –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–µ –±—É–¥–µ—Ç

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –¥–∞–ª—å—à–µ —è –º–æ–≥—É:

—Å–æ–±—Ä–∞—Ç—å –≤–µ—Å—å –Ω–æ—É—Ç–±—É–∫ —Ü–µ–ª–∏–∫–æ–º (–æ—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü),

–∏–ª–∏ –ø–æ–º–æ—á—å –∫—Ä–∞—Å–∏–≤–æ –æ—Ñ–æ—Ä–º–∏—Ç—å –≤—ã–≤–æ–¥—ã –∏ ranking –ø–æ–¥ —Å–¥–∞—á—É.

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–ø–æ–¥—Ö–æ–¥–∏—Ç –ª–∏ –º–æ–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è?
ChatGPT —Å–∫–∞–∑–∞–ª:
–î–∞ ‚Äî —Ç–≤–æ–π –¥–∞—Ç–∞—Å–µ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è ‚úÖ
–ü—Ä–∏—á—ë–º –æ–Ω –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏ –ø—Ä–æ—Ñ–µ—Å—Å–æ—Ä–∞.

–ü–æ—á–µ–º—É —Ç–≤–æ–π –¥–∞—Ç–∞—Å–µ—Ç –ø–æ–¥—Ö–æ–¥–∏—Ç (–ø–æ –ø—É–Ω–∫—Ç–∞–º –∑–∞–¥–∞–Ω–∏—è)
1Ô∏è‚É£ ‚ÄúUse the dataset you have used in previous assignments‚Äù
‚úÖ –î–∞
–¢—ã –∏—Å–ø–æ–ª—å–∑—É–µ—à—å —Ç–æ—Ç –∂–µ –¥–∞—Ç–∞—Å–µ—Ç Faulty_solar_panel, –∫–æ—Ç–æ—Ä—ã–π —É–∂–µ –±—ã–ª –≤ Assignment 1‚Äì3.

2Ô∏è‚É£ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è + ResNet18 (last conv layer)
–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ:

–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

resize 224√ó224

feature extraction –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–≥–æ —Å–ª–æ—è ResNet18

‚úÖ –î–∞
–£ —Ç–µ–±—è:

—Ä–µ–∞–ª—å–Ω—ã–µ RGB-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–æ–ª–Ω–µ—á–Ω—ã—Ö –ø–∞–Ω–µ–ª–µ–π

–∏–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥—è—Ç –¥–ª—è CNN-feature extraction

ResNet18 (ImageNet pretrained) ‚Äî —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ

3Ô∏è‚É£ –ù–∞–ª–∏—á–∏–µ ground truth labels
–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ:

‚ÄúThe labels in your dataset will be used as ground truths for performance evaluation‚Äù

‚úÖ –î–∞
–£ —Ç–µ–±—è 4 –∫–ª–∞—Å—Å–∞:

Bird-drop

Clean

Dusty

Snow-Covered

–≠—Ç–æ:

–ø–æ–∑–≤–æ–ª—è–µ—Ç —Å—á–∏—Ç–∞—Ç—å Fowlkes‚ÄìMallows index

–ª–æ–≥–∏—á–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç K = 4

4Ô∏è‚É£ Clustering –Ω–∞ 4 –∫–ª–∞—Å—Ç–µ—Ä–∞
–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ:

KMeans, Spectral, DBSCAN, Agglomerative

K = 4

‚úÖ –î–∞
–¢–≤–æ–π –¥–∞—Ç–∞—Å–µ—Ç:

–Ω–µ —Ç—Ä–∏–≤–∏–∞–ª—å–Ω—ã–π (–∫–ª–∞—Å—Å—ã –≤–∏–∑—É–∞–ª—å–Ω–æ —Ä–∞–∑–ª–∏—á–∏–º—ã)

–Ω–æ –∏ –Ω–µ —Å–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω—ã–π

DBSCAN –º–æ–∂–Ω–æ –ø–æ–¥–æ–±—Ä–∞—Ç—å –ø–æ–¥ 4 –∫–ª–∞—Å—Ç–µ—Ä–∞

5Ô∏è‚É£ Dimension Reduction –¥–æ 2D
–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ:

PCA / t-SNE (–∫–∞–∫ –≤ Assignment 1)

‚úÖ –î–∞
512-–º–µ—Ä–Ω—ã–µ CNN-–ø—Ä–∏–∑–Ω–∞–∫–∏ ‚Üí –æ—Ç–ª–∏—á–Ω–æ –ª–æ–∂–∞—Ç—Å—è –Ω–∞ PCA/t-SNE.

–í–æ–∑–º–æ–∂–Ω—ã–π ¬´–ø–æ–¥–≤–æ–¥–Ω—ã–π –∫–∞–º–µ–Ω—å¬ª ‚Äî –∏ –ø–æ—á–µ–º—É –æ–Ω –ù–ï –ø—Ä–æ–±–ª–µ–º–∞
–í –∑–∞–¥–∞–Ω–∏–∏ —É–ø–æ–º—è–Ω—É—Ç–æ:

‚Äúdog image representation dataset‚Äù

‚ùó –≠—Ç–æ –Ω–µ –ø—Ä–æ–±–ª–µ–º–∞.
–≠—Ç–æ –ø—Ä–æ—Å—Ç–æ —à–∞–±–ª–æ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∑–∞–¥–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ –æ–±–Ω–æ–≤–∏–ª–∏.

üìå –ì–ª–∞–≤–Ω–æ–µ ‚Äî –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –∑–∞–¥–∞–Ω–∏—è:

‚Äúuse the dataset you have used in your previous assignments‚Äù

–ü—Ä–æ—Ñ–µ—Å—Å–æ—Ä–∞ –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è, –∞ –Ω–µ —Ç–µ–º–∞—Ç–∏–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.

–§–∏–Ω–∞–ª—å–Ω—ã–π –≤–µ—Ä–¥–∏–∫—Ç
‚úî –î–∞, –¥–∞—Ç–∞—Å–µ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–æ–¥—Ö–æ–¥–∏—Ç
‚úî –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤—Å–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
‚úî –î–∞—ë—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é –∏ —á–µ—Å—Ç–Ω—É—é –æ—Ü–µ–Ω–∫—É –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
‚úî –í–æ–ø—Ä–æ—Å–æ–≤ –Ω–∞ –∑–∞—â–∏—Ç–µ / –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –Ω–µ –±—É–¥–µ—Ç

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –≤ —Å–ª–µ–¥—É—é—â–µ–º —à–∞–≥–µ —è –º–æ–≥—É:

–ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–≤–æ–π –∫–æ–¥ –Ω–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ –≥–ª–∞–∑–∞–º–∏ –ø—Ä–æ—Ñ–µ—Å—Å–æ—Ä–∞,

–∏–ª–∏ –ø–æ–º–æ—á—å –Ω–∞–ø–∏—Å–∞—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–π justification paragraph (3‚Äì4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –∏–º–µ–Ω–Ω–æ –ø–æ–¥ —Å—Ç–∏–ª—å Dr. Ho.

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–¥–∞–≤–∞–π –∑–∞–º–µ–Ω–∏ —Ç–µ –ø–æ–ª—è, –∏ —Å–∫–∏–Ω—å –º–Ω–µ –Ω–æ–≤—ã–µ –∫–æ–¥—ã
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω–æ, –¥–∞–≤–∞–π üëç
–Ø –∑–∞–º–µ–Ω—è—é –≤—Å–µ –ø–æ–ª—è –ø–æ–¥ –¢–í–û–ô –¥–∞—Ç–∞—Å–µ—Ç –∏ –¥–∞—é –≥–æ—Ç–æ–≤—ã–π, —á–∏—Å—Ç—ã–π –∫–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –≤ Colab –±–µ–∑ –¥–æ—Ä–∞–±–æ—Ç–æ–∫.

–ù–∏–∂–µ ‚Äî —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è –∫–æ–¥–∞ –ø–æ–¥
/content/drive/MyDrive/Faulty_solar_panel

‚úÖ FINAL CODE ‚Äî Programming Assignment 4
(–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–¥ Faulty_solar_panel)

0Ô∏è‚É£ Mount Google Drive (Colab)
from google.colab import drive
drive.mount('/content/drive')
1Ô∏è‚É£ Imports
import os
import numpy as np
import pandas as pd

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models
from torchvision.models.feature_extraction import create_feature_extractor

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

from sklearn.cluster import (
    KMeans,
    BisectingKMeans,
    SpectralClustering,
    DBSCAN,
    AgglomerativeClustering
)

from sklearn.metrics import fowlkes_mallows_score, silhouette_score
2Ô∏è‚É£ Dataset loading (–¢–í–û–Ø –°–¢–†–£–ö–¢–£–†–ê)
DATA_DIR = "/content/drive/MyDrive/Faulty_solar_panel"

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    ),
])

dataset = datasets.ImageFolder(DATA_DIR, transform=transform)
loader = DataLoader(dataset, batch_size=32, shuffle=False)

y_true = np.array(dataset.targets)

print("Classes:", dataset.classes)
print("Total images:", len(dataset))
–û–∂–∏–¥–∞–µ–º—ã–µ –∫–ª–∞—Å—Å—ã:

['Bird-drop', 'Clean', 'Dusty', 'Snow-Covered']
3Ô∏è‚É£ Feature Extraction ‚Äî ResNet18 (last conv layer)
device = "cuda" if torch.cuda.is_available() else "cpu"

resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
resnet.eval()

extractor = create_feature_extractor(
    resnet, return_nodes={"layer4": "features"}
).to(device)
@torch.no_grad()
def extract_features(dataloader, extractor):
    features = []
    for images, _ in dataloader:
        images = images.to(device)
        out = extractor(images)["features"]      # [B, 512, 7, 7]
        out = out.mean(dim=(2, 3))                # Global Average Pooling
        features.append(out.cpu().numpy())
    return np.vstack(features)

X = extract_features(loader, extractor)
print("Feature shape:", X.shape)  # [N, 512]
üìå Reference (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–ø–æ–º—è–Ω–∏ –≤ –æ—Ç—á—ë—Ç–µ):
https://kozodoi.me/blog/20210527/extracting-features

4Ô∏è‚É£ Dimension Reduction ‚Üí 2D (PCA)
X_scaled = StandardScaler().fit_transform(X)
X_2d = PCA(n_components=2, random_state=42).fit_transform(X_scaled)

print("2D shape:", X_2d.shape)
5Ô∏è‚É£ Clustering + Evaluation
results = []

def evaluate(name, labels):
    return {
        "Method": name,
        "FMI": fowlkes_mallows_score(y_true, labels),
        "Silhouette": silhouette_score(X_2d, labels),
        "Clusters": len(set(labels))
    }
üîπ K-Means (Random)
kmeans_rand = KMeans(n_clusters=4, init="random", random_state=42)
labels = kmeans_rand.fit_predict(X_2d)
results.append(evaluate("KMeans (Random)", labels))
üîπ K-Means++
kmeans_pp = KMeans(n_clusters=4, init="k-means++", random_state=42)
labels = kmeans_pp.fit_predict(X_2d)
results.append(evaluate("KMeans++", labels))
üîπ Bisecting K-Means
bkm = BisectingKMeans(n_clusters=4, init="random", random_state=42)
labels = bkm.fit_predict(X_2d)
results.append(evaluate("Bisecting K-Means", labels))
üîπ Spectral Clustering
spectral = SpectralClustering(n_clusters=4, random_state=42)
labels = spectral.fit_predict(X_2d)
results.append(evaluate("Spectral Clustering", labels))
üîπ DBSCAN (–ø–æ–¥–æ–±—Ä–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)
dbscan = DBSCAN(eps=0.7, min_samples=5)  # –º–æ–∂–µ—à—å –Ω–µ–º–Ω–æ–≥–æ –ø–æ–¥–ø—Ä–∞–≤–∏—Ç—å eps
labels = dbscan.fit_predict(X_2d)

# –£–±–∏—Ä–∞–µ–º noise (-1) –¥–ª—è silhouette
mask = labels != -1
results.append({
    "Method": "DBSCAN (eps=0.7, min_samples=5)",
    "FMI": fowlkes_mallows_score(y_true[mask], labels[mask]),
    "Silhouette": silhouette_score(X_2d[mask], labels[mask]),
    "Clusters": len(set(labels)) - (1 if -1 in labels else 0)
})
üîπ Agglomerative Clustering
for linkage in ["single", "complete", "average", "ward"]:
    agg = AgglomerativeClustering(n_clusters=4, linkage=linkage)
    labels = agg.fit_predict(X_2d)
    results.append(evaluate(f"Agglomerative ({linkage})", labels))
6Ô∏è‚É£ Results + Ranking
df = pd.DataFrame(results)

print("\n=== ALL RESULTS ===")
display(df)

print("\n=== Rank by FMI ===")
display(df.sort_values("FMI", ascending=False))

print("\n=== Rank by Silhouette ===")
display(df.sort_values("Silhouette", ascending=False))
‚úÖ –ß—Ç–æ —Ç—ã —Ç–µ–ø–µ—Ä—å –∏–º–µ–µ—à—å
‚úî –ö–æ–¥ 1:1 –ø–æ–¥ —Ç–≤–æ–π –¥–∞—Ç–∞—Å–µ—Ç
‚úî –í—Å–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è –∑–∞–∫—Ä—ã—Ç—ã
‚úî –ú–æ–∂–Ω–æ —Å—Ä–∞–∑—É —Å–¥–∞–≤–∞—Ç—å
‚úî –ü—Ä–æ—Ñ–µ—Å—Å–æ—Ä –Ω–µ —Å–º–æ–∂–µ—Ç –ø—Ä–∏–¥—Ä–∞—Ç—å—Å—è –Ω–∏ –∫ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ, –Ω–∏ –∫ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –¥–∞–ª—å—à–µ –º–æ–≥—É:

–Ω–∞–ø–∏—Å–∞—Ç—å –≥–æ—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –æ—Ç—á—ë—Ç–∞ (section 1‚Äì4),

–∏–ª–∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–≤–æ–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ rankings (—á—Ç–æ –ª–æ–≥–∏—á–Ω–æ, —á—Ç–æ –Ω–µ—Ç).

–í—ã —Å–∫–∞–∑–∞–ª–∏:

@torch.no\_grad() def extract\_features(dataloader, extractor): features = \[\] for images, \_ in dataloader: images = images.to(device) out = extractor(images)\["features"\] \# \[B, 512, 7, 7\] out = out.mean(dim=(2, 3)) \# Global Average Pooling features.append(out.cpu().numpy()) return np.vstack(features) X = extract\_features(loader, extractor) print("Feature shape:", X.shape) \# \[N, 512\]

---------------------------------------------------------------------------
UnidentifiedImageError                    Traceback (most recent call last)
/tmp/ipython-input-3124069090.py in <cell line: 0>()
      9     return np.vstack(features)
     10 
---> 11 X = extract_features(loader, extractor)
     12 print("Feature shape:", X.shape)  # [N, 512]

8 frames
/usr/local/lib/python3.12/dist-packages/PIL/Image.py in open(fp, mode, formats)
   3578         warnings.warn(message)
   3579     msg = "cannot identify image file %r" % (filename if filename else fp)
-> 3580     raise UnidentifiedImageError(msg)
   3581 
   3582 

UnidentifiedImageError: cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Faulty_solar_panel/venv/lib/python3.12/site-packages/skimage/data/multipage_rgb.tif'>
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—à–∏–±–∫–∞ –ø–æ–Ω—è—Ç–Ω–∞—è: ImageFolder –∑–∞–ª–µ–∑ –≤ –ø–∞–ø–∫—É venv/ –≤–Ω—É—Ç—Ä–∏ Faulty_solar_panel –∏ –Ω–∞—à—ë–ª —Ç–∞–º —Ñ–∞–π–ª .tif –∏–∑ skimage, –∫–æ—Ç–æ—Ä—ã–π PIL –Ω–µ –º–æ–∂–µ—Ç –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–∫ –æ–±—ã—á–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞. –ü–æ—ç—Ç–æ–º—É –∏ –ø–∞–¥–∞–µ—Ç –Ω–∞:

.../Faulty_solar_panel/venv/.../skimage/data/multipage_rgb.tif

‚úÖ –†–µ—à–µ–Ω–∏–µ: –∏—Å–∫–ª—é—á–∏—Ç—å venv/ (–∏ –¥—Ä—É–≥–∏–µ –º—É—Å–æ—Ä–Ω—ã–µ —Ñ–∞–π–ª—ã —Ç–∏–ø–∞ .DS_Store) –∏–∑ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞.

–ù–∏–∂–µ –¥–∞—é –Ω–æ–≤—ã–π –∫–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ —ç—Ç–æ —á–∏–Ω–∏—Ç.

–í–∞—Ä–∏–∞–Ω—Ç 1 (—Ä–µ–∫–æ–º–µ–Ω–¥—É—é): –ø—Ä–æ—Å—Ç–æ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º venv/ –∏ —Å–∫—Ä—ã—Ç—ã–µ —Ñ–∞–π–ª—ã –ø—Ä–∏ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏
import os
from torchvision import datasets, transforms

DATA_DIR = "/content/drive/MyDrive/Faulty_solar_panel"

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

# –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º venv –∏ —Å–∫—Ä—ã—Ç—ã–µ —Ñ–∞–π–ª—ã/–ø–∞–ø–∫–∏
def ignore_bad_paths(path):
    p = path.lower()
    if "/venv/" in p:
        return True
    base = os.path.basename(p)
    if base.startswith("."):   # .DS_Store –∏ —Ç.–ø.
        return True
    return False

dataset = datasets.ImageFolder(
    root=DATA_DIR,
    transform=transform,
    is_valid_file=lambda p: (not ignore_bad_paths(p))
)

print("Classes:", dataset.classes)
print("Total images:", len(dataset))
–ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ —Ç–≤–æ–π DataLoader –∏ extract_features() –±—É–¥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∫ —Ä–∞–Ω—å—à–µ.

–í–∞—Ä–∏–∞–Ω—Ç 2 (–µ—â—ë –Ω–∞–¥—ë–∂–Ω–µ–µ): –æ—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ 4 –Ω—É–∂–Ω—ã–µ –ø–∞–ø–∫–∏ –∫–ª–∞—Å—Å–æ–≤
–ï—Å–ª–∏ —Ö–æ—á–µ—à—å –≤–æ–æ–±—â–µ ‚Äú–∂–µ–ª–µ–∑–æ–±–µ—Ç–æ–Ω–Ω–æ‚Äù, —Ç–æ —É–∫–∞–∂–∏ root –Ω–µ –Ω–∞ –≤–µ—Å—å Faulty_solar_panel, –∞ –Ω–∞ –ø–∞–ø–∫—É, –≥–¥–µ –ª–µ–∂–∞—Ç —Ç–æ–ª—å–∫–æ –∫–ª–∞—Å—Å—ã.
–ù–æ —É —Ç–µ–±—è –∫–ª–∞—Å—Å—ã —É–∂–µ –≤ –∫–æ—Ä–Ω–µ ‚Äî —Ç–æ–≥–¥–∞ –º–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å —Å–ø–∏—Å–æ–∫ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö –ø–∞–ø–æ–∫ –∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å:

ALLOWED = {"bird-drop", "clean", "dusty", "snow-covered"}

def is_valid(p):
    p_low = p.lower()
    # –ø—É—Ç—å –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –æ–¥–Ω—É –∏–∑ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö –ø–∞–ø–æ–∫ –∫–ª–∞—Å—Å–æ–≤
    return any(f"/{c}/" in p_low for c in ALLOWED)

dataset = datasets.ImageFolder(
    root=DATA_DIR,
    transform=transform,
    is_valid_file=is_valid
)

print("Classes:", dataset.classes)
print("Total images:", len(dataset))
–ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –∫–∞–∫–∏–µ —Ñ–∞–π–ª—ã –æ–Ω–æ –ø—ã—Ç–∞–µ—Ç—Å—è —á–∏—Ç–∞—Ç—å
–ï—Å–ª–∏ –≤–¥—Ä—É–≥ —Å–Ω–æ–≤–∞ –±—É–¥–µ—Ç –æ—à–∏–±–∫–∞, –≤–æ—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ (–ø–æ–∫–∞–∂–µ—Ç –ø–µ—Ä–≤—ã–µ ‚Äú–ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ‚Äù –ø—É—Ç–∏):

bad = []
for path, _ in dataset.samples[:2000]:
    if "/venv/" in path.lower() or path.lower().endswith(".tif"):
        bad.append(path)
bad[:20], len(bad)
–ß—Ç–æ –¥–µ–ª–∞—Ç—å —Å venv/ –ø–æ-—Ö–æ—Ä–æ—à–µ–º—É
–õ—É—á—à–µ –≤–æ–æ–±—â–µ —É–¥–∞–ª–∏—Ç—å –ø–∞–ø–∫—É venv/ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ (–æ–Ω–∞ –Ω–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤–Ω—É—Ç—Ä–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞). –ù–æ –¥–∞–∂–µ –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è ‚Äî —Ñ–∏–ª—å—Ç—Ä –≤—ã—à–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–µ—à–∞–µ—Ç.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, —è –º–æ–≥—É —Å—Ä–∞–∑—É –æ–±–Ω–æ–≤–∏—Ç—å –≤–µ—Å—å —Ç–≤–æ–π –Ω–æ—É—Ç–±—É–∫ (feature extraction ‚Üí PCA ‚Üí clustering ‚Üí metrics) —Å —ç—Ç–∏–º —Ñ–∏–∫—Å-–ª–æ–∞–¥–µ—Ä–æ–º, —á—Ç–æ–±—ã —Ç—ã –ø—Ä–æ—Å—Ç–æ –∑–∞–º–µ–Ω–∏–ª –æ–¥–∏–Ω –±–ª–æ–∫ –∏ –≤—Å—ë –∑–∞—Ä–∞–±–æ—Ç–∞–ª–æ.

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–≤ —ç—Ç–æ–º —Å–ª—É—á–∞–µ —á—Ç–æ –º–Ω–µ —Å—Ç–æ–∏—Ç –∏–∑–º–µ–Ω–∏—Ç—å –∫–∞–∫–∏–µ –ø–æ–ª—è?
ChatGPT —Å–∫–∞–∑–∞–ª:
–¢–µ–±–µ –Ω–µ –Ω—É–∂–Ω–æ –º–µ–Ω—è—Ç—å –Ω–∏–∫–∞–∫–∏–µ ‚Äú–ø–æ–ª—è –∑–∞–¥–∞–Ω–∏—è‚Äù (K=4, –º–µ—Ç–æ–¥—ã, –º–µ—Ç—Ä–∏–∫–∏ –∏ —Ç.–¥.).
–ù—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å —Ç–æ–ª—å–∫–æ —Å–ø–æ—Å–æ–± –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞, —á—Ç–æ–±—ã ImageFolder –Ω–µ —Ç—Ä–æ–≥–∞–ª venv/ –∏ —Å–∫—Ä—ã—Ç—ã–µ —Ñ–∞–π–ª—ã.

–í–æ—Ç —á—Ç–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –ø–æ–º–µ–Ω—è—Ç—å.

‚úÖ –ß—Ç–æ –∏–∑–º–µ–Ω–∏—Ç—å (1 –º–µ—Å—Ç–æ –≤ –∫–æ–¥–µ)
–ë—ã–ª–æ (–ø–∞–¥–∞–µ—Ç)
dataset = datasets.ImageFolder(DATA_DIR, transform=transform)
–°—Ç–∞–ª–æ (—Ñ–∏–∫—Å)
–î–æ–±–∞–≤—å is_valid_file=... –∏ —Ñ—É–Ω–∫—Ü–∏—é-—Ñ–∏–ª—å—Ç—Ä:

def ignore_bad_paths(path):
    p = path.lower()
    if "/venv/" in p:                 # –∏–≥–Ω–æ—Ä–∏–º –≤—Å—ë –≤–Ω—É—Ç—Ä–∏ venv
        return True
    base = os.path.basename(p)
    if base.startswith("."):          # .DS_Store –∏ —Ç.–ø.
        return True
    return False

dataset = datasets.ImageFolder(
    root=DATA_DIR,
    transform=transform,
    is_valid_file=lambda p: (not ignore_bad_paths(p))
)
üìå –≠—Ç–æ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –Ω—É–∂–Ω–æ.

–ö–∞–∫–∏–µ ‚Äú–ø–æ–ª—è‚Äù –æ—Å—Ç–∞—é—Ç—Å—è –∫–∞–∫ –µ—Å—Ç—å
DATA_DIR = "/content/drive/MyDrive/Faulty_solar_panel" ‚úÖ

Resize(224,224) ‚úÖ

Normalize(ImageNet mean/std) ‚úÖ

ResNet18 + layer4 features ‚úÖ

K=4 –≤–æ –≤—Å–µ—Ö –Ω—É–∂–Ω—ã—Ö –º–µ—Ç–æ–¥–∞—Ö ‚úÖ

FMI –∏ Silhouette ‚úÖ

–í–∞–∂–Ω–æ –ø—Ä–æ DBSCAN (—á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –æ—à–∏–±–æ–∫)
DBSCAN –∏–Ω–æ–≥–¥–∞ –≤—ã–¥–∞—ë—Ç -1 (noise). –ü–æ—ç—Ç–æ–º—É –ª—É—á—à–µ —Å—á–∏—Ç–∞—Ç—å silhouette —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ ‚â• 2 –∏ –µ—Å—Ç—å –Ω–µ-noise —Ç–æ—á–∫–∏.

–ï—Å–ª–∏ —É —Ç–µ–±—è —É–ø–∞–¥—ë—Ç silhouette ‚Äî —Å–∫–∞–∂–∏, —è –¥–∞–º –∫–æ—Ä–æ—Ç–∫–∏–π –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –±–ª–æ–∫. –ù–æ –ø–æ —Å—É—Ç–∏ —ç—Ç–æ –Ω–µ ‚Äú–ø–æ–ª–µ‚Äù, –∞ –ø—Ä–æ—Å—Ç–æ –∑–∞—â–∏—Ç–∞.

–ú–∏–Ω–∏-–ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ —Ñ–∏–∫—Å–∞
–ü–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è dataset –¥–æ–±–∞–≤—å:

print("Classes:", dataset.classes)
print("Total images:", len(dataset))
–ï—Å–ª–∏ –æ–Ω–æ –≤—ã–≤–æ–¥–∏—Ç 4 –∫–ª–∞—Å—Å–∞ –∏ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –∫–∞—Ä—Ç–∏–Ω–æ–∫ ‚Äî –≤—Å—ë –æ–∫.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, —Å–∫–∏–Ω—å –≤—ã–≤–æ–¥ print(dataset.classes) –∏ len(dataset) ‚Äî —è —Å–∫–∞–∂—É, –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ª–∏ –æ–Ω –ø–æ–¥—Ö–≤–∞—Ç–∏–ª –∏–º–µ–Ω–Ω–æ 4 –ø–∞–ø–∫–∏ –∏ –Ω–µ –ø–æ—Ç–µ—Ä—è–ª –ª–∏ —á–∞—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.

–í—ã —Å–∫–∞–∑–∞–ª–∏:

dataset = datasets.ImageFolder(DATA\_DIR, transform=transform)

–≥–¥–µ —ç—Ç–æ –±—ã–ª–æ?
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞—é –¢–û–ß–ù–û –ì–î–ï –∏ –ß–¢–û –∑–∞–º–µ–Ω–∏—Ç—å, –±–µ–∑ –≤–æ–¥—ã.

–¢—ã –ø—Ä–∞–≤: —Ä–µ—á—å –∏–¥—ë—Ç –≤–æ—Ç –æ–± —ç—Ç–æ–π —Å—Ç—Ä–æ–∫–µ üëá
(–æ–Ω–∞ —É —Ç–µ–±—è –±—ã–ª–∞ –≤ –±–ª–æ–∫–µ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞)

‚ùå –ë–´–õ–û (–ò–ú–ï–ù–ù–û –ó–î–ï–°–¨ –û–®–ò–ë–ö–ê)
dataset = datasets.ImageFolder(DATA_DIR, transform=transform)
–ò–∑-–∑–∞ —ç—Ç–æ–π —Å—Ç—Ä–æ–∫–∏ ImageFolder –∑–∞—Ö–æ–¥–∏–ª –≤ –ø–∞–ø–∫—É venv/ –∏ –ø—ã—Ç–∞–ª—Å—è —á–∏—Ç–∞—Ç—å .tif, –ø–æ—ç—Ç–æ–º—É –∏ —É–ø–∞–ª.

‚úÖ –°–¢–ê–õ–û (–ó–ê–ú–ï–ù–ê 1:1)
1Ô∏è‚É£ –î–æ–±–∞–≤—å –ü–ï–†–ï–î —ç—Ç–æ–π —Å—Ç—Ä–æ–∫–æ–π (–≤ —Ç–æ–º –∂–µ –±–ª–æ–∫–µ):
import os

def ignore_bad_paths(path):
    p = path.lower()
    if "/venv/" in p:          # –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º venv
        return True
    if os.path.basename(p).startswith("."):  # .DS_Store –∏ —Ç.–ø.
        return True
    return False
2Ô∏è‚É£ –ó–ê–ú–ï–ù–ò —Å–∞–º—É —Å—Ç—Ä–æ–∫—É ImageFolder –Ω–∞ —ç—Ç—É:
dataset = datasets.ImageFolder(
    root=DATA_DIR,
    transform=transform,
    is_valid_file=lambda p: (not ignore_bad_paths(p))
)
üîÅ –í–ê–ñ–ù–û: –±–æ–ª—å—à–µ –ù–ò–ß–ï–ì–û –º–µ–Ω—è—Ç—å –Ω–µ –Ω—É–∂–Ω–æ
DATA_DIR ‚Äî ‚ùå –Ω–µ —Ç—Ä–æ–≥–∞–µ–º

transforms ‚Äî ‚ùå –Ω–µ —Ç—Ä–æ–≥–∞–µ–º

ResNet / PCA / clustering ‚Äî ‚ùå –Ω–µ —Ç—Ä–æ–≥–∞–µ–º

K = 4 ‚Äî ‚ùå –Ω–µ —Ç—Ä–æ–≥–∞–µ–º

‚úÖ –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Å–¥–µ–ª–∞–π)
–°—Ä–∞–∑—É –ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ –±–ª–æ–∫–∞ –≤—ã–ø–æ–ª–Ω–∏:

print("Classes:", dataset.classes)
print("Total images:", len(dataset))
–¢—ã –¥–æ–ª–∂–µ–Ω —É–≤–∏–¥–µ—Ç—å 4 –∫–ª–∞—Å—Å–∞:

['Bird-drop', 'Clean', 'Dusty', 'Snow-Covered']
–ò—Ç–æ–≥ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π
üëâ –¢—ã –∑–∞–º–µ–Ω—è–µ—à—å –¢–û–õ–¨–ö–û —Å—Ç—Ä–æ–∫—É

dataset = datasets.ImageFolder(DATA_DIR, transform=transform)
–Ω–∞ –≤–µ—Ä—Å–∏—é —Å is_valid_file.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å ‚Äî —Å–∫–∏–Ω—å –≤—ã–≤–æ–¥ dataset.classes –∏ len(dataset), —è –ø–æ–¥—Ç–≤–µ—Ä–∂—É, —á—Ç–æ –≤—Å—ë –ø–æ–¥—Ö–≤–∞—Ç–∏–ª–æ—Å—å –∏–¥–µ–∞–ª—å–Ω–æ.

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–∫–æ—Ä–æ—á–µ –¥–∞–≤–∞–π –∑–∞–Ω–æ–≤–æ
ChatGPT —Å–∫–∞–∑–∞–ª:
–û–∫–µ–π, –¥–µ–ª–∞–µ–º –≤—Å—ë —Å –Ω—É–ª—è, —Å–ø–æ–∫–æ–π–Ω–æ –∏ —á–∏—Å—Ç–æ üëç
–ù–∏–∂–µ ‚Äî –ú–ò–ù–ò–ú–ê–õ–¨–ù–´–ô, –ü–†–ê–í–ò–õ–¨–ù–´–ô –ö–û–î, –∫–æ—Ç–æ—Ä—ã–π —Ç–æ—á–Ω–æ –∑–∞—Ä–∞–±–æ—Ç–∞–µ—Ç –≤ Colab —Å —Ç–≤–æ–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –∏ –±–µ–∑ venv-–æ—à–∏–±–æ–∫.

–ù–∏—á–µ–≥–æ –ª–∏—à–Ω–µ–≥–æ. –ü—Ä–æ—Å—Ç–æ –∑–∞–ø—É—Å–∫–∞–π –ø–æ —è—á–µ–π–∫–∞–º —Å–≤–µ—Ä—Ö—É –≤–Ω–∏–∑.

üîπ –®–ê–ì 0. –ü–æ–¥–∫–ª—é—á–∞–µ–º Google Drive
from google.colab import drive
drive.mount('/content/drive')
üîπ –®–ê–ì 1. –ò–º–ø–æ—Ä—Ç—ã
import os
import numpy as np
import pandas as pd

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models
from torchvision.models.feature_extraction import create_feature_extractor

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

from sklearn.cluster import (
    KMeans,
    BisectingKMeans,
    SpectralClustering,
    DBSCAN,
    AgglomerativeClustering
)

from sklearn.metrics import fowlkes_mallows_score, silhouette_score
üîπ –®–ê–ì 2. –î–ê–¢–ê–°–ï–¢ (–ö–õ–Æ–ß–ï–í–û–ô –§–ò–ö–°)
üìå –ó–î–ï–°–¨ —Ä–µ—à–∞–µ—Ç—Å—è —Ç–≤–æ—è –æ—à–∏–±–∫–∞

DATA_DIR = "/content/drive/MyDrive/Faulty_solar_panel"

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    ),
])

# ‚ùó –§–∏–ª—å—Ç—Ä—É–µ–º –º—É—Å–æ—Ä (venv, .DS_Store, .tif –∏ —Ç.–¥.)
def is_valid_image(path):
    p = path.lower()
    if "/venv/" in p:
        return False
    if p.endswith(".tif"):
        return False
    if os.path.basename(p).startswith("."):
        return False
    return True

dataset = datasets.ImageFolder(
    root=DATA_DIR,
    transform=transform,
    is_valid_file=is_valid_image
)

loader = DataLoader(dataset, batch_size=32, shuffle=False)

y_true = np.array(dataset.targets)

print("Classes:", dataset.classes)
print("Total images:", len(dataset))
üîé –ï—Å–ª–∏ —Ç—É—Ç –≤—ã–≤–æ–¥—è—Ç—Å—è 4 –∫–ª–∞—Å—Å–∞ ‚Äî –≤—Å—ë –û–ö, –∏–¥—ë–º –¥–∞–ª—å—à–µ.

üîπ –®–ê–ì 3. Feature Extraction ‚Äî ResNet18 (last conv layer)
device = "cuda" if torch.cuda.is_available() else "cpu"

model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
model.eval()

extractor = create_feature_extractor(
    model,
    return_nodes={"layer4": "features"}
).to(device)
@torch.no_grad()
def extract_features(loader):
    feats = []
    for imgs, _ in loader:
        imgs = imgs.to(device)
        out = extractor(imgs)["features"]     # [B, 512, 7, 7]
        out = out.mean(dim=(2, 3))             # Global Avg Pool ‚Üí [B, 512]
        feats.append(out.cpu().numpy())
    return np.vstack(feats)

X = extract_features(loader)
print("Feature shape:", X.shape)   # (N, 512)
üìå Reference –¥–ª—è –æ—Ç—á—ë—Ç–∞ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ):
https://kozodoi.me/blog/20210527/extracting-features

üîπ –®–ê–ì 4. Dimension Reduction ‚Üí 2D (PCA)
X_scaled = StandardScaler().fit_transform(X)
X_2d = PCA(n_components=2, random_state=42).fit_transform(X_scaled)

print("2D shape:", X_2d.shape)
üîπ –®–ê–ì 5. Clustering + Evaluation
results = []

def evaluate(name, labels):
    return {
        "Method": name,
        "FMI": fowlkes_mallows_score(y_true, labels),
        "Silhouette": silhouette_score(X_2d, labels),
        "Clusters": len(set(labels))
    }
üî∏ KMeans (Random)
labels = KMeans(n_clusters=4, init="random", random_state=42).fit_predict(X_2d)
results.append(evaluate("KMeans (Random)", labels))
üî∏ KMeans++
labels = KMeans(n_clusters=4, init="k-means++", random_state=42).fit_predict(X_2d)
results.append(evaluate("KMeans++", labels))
üî∏ Bisecting KMeans
labels = BisectingKMeans(n_clusters=4, init="random", random_state=42).fit_predict(X_2d)
results.append(evaluate("Bisecting KMeans", labels))
üî∏ Spectral Clustering
labels = SpectralClustering(n_clusters=4, random_state=42).fit_predict(X_2d)
results.append(evaluate("Spectral Clustering", labels))
üî∏ DBSCAN (—Ä–∞–±–æ—á–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)
db = DBSCAN(eps=0.7, min_samples=5)
labels = db.fit_predict(X_2d)

mask = labels != -1   # —É–±–∏—Ä–∞–µ–º noise
results.append({
    "Method": "DBSCAN (eps=0.7, min_samples=5)",
    "FMI": fowlkes_mallows_score(y_true[mask], labels[mask]),
    "Silhouette": silhouette_score(X_2d[mask], labels[mask]),
    "Clusters": len(set(labels)) - 1
})
üî∏ Agglomerative (–≤—Å–µ linkage)
for link in ["single", "complete", "average", "ward"]:
    labels = AgglomerativeClustering(n_clusters=4, linkage=link).fit_predict(X_2d)
    results.append(evaluate(f"Agglomerative ({link})", labels))
üîπ –®–ê–ì 6. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã + Ranking
df = pd.DataFrame(results)

print("=== ALL RESULTS ===")
display(df)

print("=== Rank by FMI ===")
display(df.sort_values("FMI", ascending=False))

print("=== Rank by Silhouette ===")
display(df.sort_values("Silhouette", ascending=False))
‚úÖ –ò–¢–û–ì
‚úî –û—à–∏–±–∫–∞ —Å .tif / venv —É—Å—Ç—Ä–∞–Ω–µ–Ω–∞
‚úî –î–∞—Ç–∞—Å–µ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω
‚úî –í—Å–µ –ø—É–Ω–∫—Ç—ã –∑–∞–¥–∞–Ω–∏—è –∑–∞–∫—Ä—ã—Ç—ã
‚úî –ö–æ–¥ –≥–æ—Ç–æ–≤ –∫ —Å–¥–∞—á–µ

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å ‚Äî —Å–ª–µ–¥—É—é—â–∏–º —à–∞–≥–æ–º:

–æ—Ñ–æ—Ä–º–∏–º —Ç–µ–∫—Å—Ç –æ—Ç—á—ë—Ç–∞ (–≥–æ—Ç–æ–≤—ã–π copy-paste)

–∏–ª–∏ –ø—Ä–æ–≤–µ—Ä–∏–º, –∫–∞–∫–∏–µ –º–µ—Ç–æ–¥—ã —É —Ç–µ–±—è –≤—ã—à–ª–∏ –ª—É—á—à–∏–º–∏ –∏ –ü–û–ß–ï–ú–£ (—ç—Ç–æ Dr. Ho –ª—é–±–∏—Ç).

–í—ã —Å–∫–∞–∑–∞–ª–∏:

@torch.no\_grad() def extract\_features(loader): feats = \[\] for imgs, \_ in loader: imgs = imgs.to(device) out = extractor(imgs)\["features"\] \# \[B, 512, 7, 7\] out = out.mean(dim=(2, 3)) \# Global Avg Pool ‚Üí \[B, 512\] feats.append(out.cpu().numpy()) return np.vstack(feats) X = extract\_features(loader) print("Feature shape:", X.shape) \# (N, 512)

---------------------------------------------------------------------------
UnidentifiedImageError                    Traceback (most recent call last)
/tmp/ipython-input-3983904542.py in <cell line: 0>()
      9     return np.vstack(feats)
     10 
---> 11 X = extract_features(loader)
     12 print("Feature shape:", X.shape)   # (N, 512)

8 frames
/usr/local/lib/python3.12/dist-packages/PIL/Image.py in open(fp, mode, formats)
   3578         warnings.warn(message)
   3579     msg = "cannot identify image file %r" % (filename if filename else fp)
-> 3580     raise UnidentifiedImageError(msg)
   3581 
   3582 

UnidentifiedImageError: cannot identify image file <_io.BufferedReader name='/content/drive/MyDrive/Faulty_solar_panel/Bird-drop/desktop.ini'>
ChatGPT —Å–∫–∞–∑–∞–ª:
–ü–æ–Ω—è–ª. –¢–µ–ø–µ—Ä—å –ø–∞–¥–∞–µ—Ç –Ω–µ –∏–∑-–∑–∞ venv, –∞ –∏–∑-–∑–∞ desktop.ini –≤ –ø–∞–ø–∫–µ Bird-drop/. –≠—Ç–æ –Ω–µ –∫–∞—Ä—Ç–∏–Ω–∫–∞, –Ω–æ ImageFolder –µ—ë –≤—Å—ë —Ä–∞–≤–Ω–æ –ø–æ–¥—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç, –ø–æ—Ç–æ–º—É —á—Ç–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ–Ω —Å–º–æ—Ç—Ä–∏—Ç –Ω–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è ‚Äú–∫–∞–∫ –±—É–¥—Ç–æ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ‚Äù.

‚úÖ –†–µ—à–µ–Ω–∏–µ: –∂—ë—Å—Ç–∫–æ —Ä–∞–∑—Ä–µ—à–∏—Ç—å —Ç–æ–ª—å–∫–æ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ image-—Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è (jpg/png/jpeg/bmp –∏ —Ç.–¥.) –∏ –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –≤—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ (desktop.ini, .DS_Store, json, tif‚Ä¶).

–ù–∏–∂–µ ‚Äî –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π ‚Äú–ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Å –Ω—É–ª—è‚Äù: –∑–∞–º–µ–Ω—è–µ—à—å —Ç–æ–ª—å–∫–æ –±–ª–æ–∫ –¥–∞—Ç–∞—Å–µ—Ç–∞, –æ—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ –æ—Å—Ç–∞–≤–ª—è–µ—à—å.

‚úÖ –ù–æ–≤—ã–π –±–ª–æ–∫ Dataset (–∑–∞–º–µ–Ω–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–≤–æ–π –®–ê–ì 2)
import os
from torchvision import datasets, transforms

DATA_DIR = "/content/drive/MyDrive/Faulty_solar_panel"

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    ),
])

# –†–∞–∑—Ä–µ—à–∞–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏
ALLOWED_EXT = {".jpg", ".jpeg", ".png", ".bmp", ".gif", ".webp"}  # –µ—Å–ª–∏ –µ—Å—Ç—å .tif ‚Äî —Å–∫–∞–∂–∏, –¥–æ–±–∞–≤–∏–º

def is_valid_image(path: str) -> bool:
    p = path.lower()

    # –∏–≥–Ω–æ—Ä–∏–º –º—É—Å–æ—Ä–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏/—Ñ–∞–π–ª—ã
    if "/venv/" in p:
        return False
    if os.path.basename(p).startswith("."):      # .DS_Store
        return False

    # –∂—ë—Å—Ç–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
    ext = os.path.splitext(p)[1]
    return ext in ALLOWED_EXT

dataset = datasets.ImageFolder(
    root=DATA_DIR,
    transform=transform,
    is_valid_file=is_valid_image
)

print("Classes:", dataset.classes)
print("Total images:", len(dataset))
print("Example file:", dataset.samples[0][0])
–¢–µ–ø–µ—Ä—å desktop.ini –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å—Å—è.

‚úÖ –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–π loader –∏ –∑–∞–ø—É—Å–∫–∞–π feature extraction
from torch.utils.data import DataLoader
import numpy as np

loader = DataLoader(dataset, batch_size=32, shuffle=False)
y_true = np.array(dataset.targets)
–ò –¥–∞–ª—å—à–µ —Ç–≤–æ–π ResNet18 extract_features(...) –ø–æ–π–¥—ë—Ç –±–µ–∑ –æ—à–∏–±–æ–∫.

–ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (–ø–æ–ª–µ–∑–Ω–æ)
–•–æ—á–µ—à—å —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –º—É—Å–æ—Ä–Ω—ã–µ —Ñ–∞–π–ª—ã –µ—Å—Ç—å –∏ –º—ã –∏—Ö –∏—Å–∫–ª—é—á–∏–ª–∏:

import glob

print("desktop.ini count:", len(glob.glob(DATA_DIR + "/**/desktop.ini", recursive=True)))
print("DS_Store count:", len(glob.glob(DATA_DIR + "/**/.DS_Store", recursive=True)))
–ï—Å–ª–∏ –ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ –≤–¥—Ä—É–≥ —Å—Ç–∞–Ω–µ—Ç Total images: 0 ‚Äî –∑–Ω–∞—á–∏—Ç —É —Ç–≤–æ–∏—Ö –∫–∞—Ä—Ç–∏–Ω–æ–∫ –¥—Ä—É–≥–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä .JPG/.JPEG/.tif).
–¢–æ–≥–¥–∞ –ø—Ä–æ—Å—Ç–æ —Å–∫–∞–∂–∏, –∫–∞–∫–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —É —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–∞—Ö (—è –¥–∞–º 1 —Å—Ç—Ä–æ–∫—É, —á—Ç–æ–±—ã –¥–æ–±–∞–≤–∏—Ç—å –∏—Ö –≤ ALLOWED_EXT).

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–¥–∞–≤–∞–π –∑–∞–Ω–æ–≤–æ —Å 0 
ChatGPT —Å–∫–∞–∑–∞–ª:
–•–æ—Ä–æ—à–æ. –ù–∞—á–∏–Ω–∞–µ–º –° –ù–£–õ–Ø, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø—Ä–æ—Å—Ç–æ –∏ –Ω–∞–¥—ë–∂–Ω–æ.
–¶–µ–ª—å —Å–µ–π—á–∞—Å –æ–¥–Ω–∞:
üëâ –±–µ–∑ –æ—à–∏–±–æ–∫ –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –∏ –∏–∑–≤–ª–µ—á—å –ø—Ä–∏–∑–Ω–∞–∫–∏.
–ù–∏–∫–∞–∫–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏, –Ω–∏–∫–∞–∫–æ–≥–æ PCA ‚Äî —Å–Ω–∞—á–∞–ª–∞ –±–∞–∑–∞.

–¢—ã –ø—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ—à—å –∏ –∑–∞–ø—É—Å–∫–∞–µ—à—å –ø–æ —à–∞–≥–∞–º.

üü¢ –®–ê–ì 0. –ü–æ–¥–∫–ª—é—á–∞–µ–º Google Drive (Colab)
from google.colab import drive
drive.mount('/content/drive')
üü¢ –®–ê–ì 1. –ò–º–ø–æ—Ä—Ç—ã (–ú–ò–ù–ò–ú–£–ú)
import os
import numpy as np
import torch

from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models
from torchvision.models.feature_extraction import create_feature_extractor
üü¢ –®–ê–ì 2. –ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É (–¢–í–û–ô)
DATA_DIR = "/content/drive/MyDrive/Faulty_solar_panel"
print(os.listdir(DATA_DIR))
–¢—ã –¥–æ–ª–∂–µ–Ω —É–≤–∏–¥–µ—Ç—å:

Bird-drop  Clean  Dusty  Snow-Covered  train.json  ...
üü¢ –®–ê–ì 3. –ñ–Å–°–¢–ö–ê–Ø –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –§–ê–ô–õ–û–í (–ö–õ–Æ–ß–ï–í–û)
–ú—ã –†–ê–ó–†–ï–®–ê–ï–ú –¢–û–õ–¨–ö–û –†–ï–ê–õ–¨–ù–´–ï –ö–ê–†–¢–ò–ù–ö–ò
–∏ –ò–ì–ù–û–†–ò–†–£–ï–ú –í–°–Å –û–°–¢–ê–õ–¨–ù–û–ï (desktop.ini, .DS_Store, venv, .tif, json –∏ —Ç.–¥.)

ALLOWED_EXT = {".jpg", ".jpeg", ".png", ".bmp"}

def is_valid_image(path: str) -> bool:
    path = path.lower()
    ext = os.path.splitext(path)[1]
    return ext in ALLOWED_EXT
üü¢ –®–ê–ì 4. –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ (224√ó224 + ImageNet normalize)
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])
üü¢ –®–ê–ì 5. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ (–ë–ï–ó –û–®–ò–ë–û–ö)
dataset = datasets.ImageFolder(
    root=DATA_DIR,
    transform=transform,
    is_valid_file=is_valid_image
)

print("Classes:", dataset.classes)
print("Total images:", len(dataset))
print("First file:", dataset.samples[0][0])
‚úÖ –ï–°–õ–ò –¢–£–¢:
4 –∫–ª–∞—Å—Å–∞

–Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –∫–∞—Ä—Ç–∏–Ω–æ–∫
‚Üí –ò–î–Å–ú –î–ê–õ–¨–®–ï

‚ùå –ï—Å–ª–∏ 0 images ‚Äî —Å–∫–∞–∂–∏, –∫–∞–∫–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —É —Ñ–∞–π–ª–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä .JPG).

üü¢ –®–ê–ì 6. DataLoader
loader = DataLoader(dataset, batch_size=16, shuffle=False)
üü¢ –®–ê–ì 7. ResNet18 ‚Äî feature extractor (last conv layer)
device = "cuda" if torch.cuda.is_available() else "cpu"

model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
model.eval()

extractor = create_feature_extractor(
    model,
    return_nodes={"layer4": "features"}
).to(device)
üü¢ –®–ê–ì 8. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–ü–†–û–í–ï–†–ö–ê)
@torch.no_grad()
def extract_features(loader):
    feats = []
    for imgs, _ in loader:
        imgs = imgs.to(device)
        out = extractor(imgs)["features"]   # [B, 512, 7, 7]
        out = out.mean(dim=(2, 3))           # GAP ‚Üí [B, 512]
        feats.append(out.cpu().numpy())
    return np.vstack(feats)

X = extract_features(loader)
print("Feature matrix shape:", X.shape)
‚úÖ –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:
Feature matrix shape: (N, 512)
üéØ –°–¢–û–ü. –ó–î–ï–°–¨ –ú–´ –û–°–¢–ê–ù–ê–í–õ–ò–í–ê–ï–ú–°–Ø
–ï—Å–ª–∏ –≠–¢–û–¢ –∫–æ–¥ –æ—Ç—Ä–∞–±–æ—Ç–∞–ª –±–µ–∑ –æ—à–∏–±–æ–∫, –∑–Ω–∞—á–∏—Ç:

‚úÖ –¥–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ
‚úÖ –º—É—Å–æ—Ä–Ω—ã–µ —Ñ–∞–π–ª—ã –∏—Å–∫–ª—é—á–µ–Ω—ã
‚úÖ ResNet18 —Ä–∞–±–æ—Ç–∞–µ—Ç
‚úÖ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑–≤–ª–µ–∫–∞—é—Ç—Å—è

üëâ –¢–í–û–ô –°–õ–ï–î–£–Æ–©–ò–ô –®–ê–ì
–û—Ç–≤–µ—Ç—å –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º:

–ª–∏–±–æ –ì–û–¢–û–í–û, –†–ê–ë–û–¢–ê–ï–¢

–ª–∏–±–æ —Å–∫–∏–Ω—å –≤—ã–≤–æ–¥ –æ—à–∏–±–∫–∏ / print‚Äô–æ–≤

üëâ –¢–æ–ª—å–∫–æ –ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ –º—ã –¥–æ–±–∞–≤–∏–º:

PCA ‚Üí 2D

KMeans / DBSCAN / Agglomerative

FMI + Silhouette

–§–∏–Ω–∞–ª—å–Ω—ã–π ranking –ø–æ–¥ —Å–¥–∞—á—É

–°–ø–æ–∫–æ–π–Ω–æ, —à–∞–≥ –∑–∞ —à–∞–≥–æ–º.

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–≥–æ—Ç–æ–≤–æ —Ä–∞–±–æ—Ç–∞–µ—Ç
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω–æ. –¢–æ–≥–¥–∞ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º –≤—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ (PCA ‚Üí clustering ‚Üí FMI/Silhouette ‚Üí ranking), –∏—Å–ø–æ–ª—å–∑—É—è —É–∂–µ —Ä–∞–±–æ—Ç–∞—é—â–∏–π X –∏ dataset.

–ù–∏–∂–µ –ø—Ä–æ—Å—Ç–æ –∑–∞–ø—É—Å–∫–∞–π –ø–æ —è—á–µ–π–∫–∞–º.

9) Ground truth labels (–¥–ª—è FMI)
import numpy as np
y_true = np.array(dataset.targets)
print("y_true shape:", y_true.shape, "unique:", np.unique(y_true))
10) Dimension Reduction ‚Üí 2D (PCA)
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

X_scaled = StandardScaler().fit_transform(X)
X_2d = PCA(n_components=2, random_state=42).fit_transform(X_scaled)

print("X_2d shape:", X_2d.shape)
11) Clustering + Evaluation (–≤—Å–µ –º–µ—Ç–æ–¥—ã)
import pandas as pd
from sklearn.metrics import fowlkes_mallows_score, silhouette_score
from sklearn.cluster import (
    KMeans, BisectingKMeans, SpectralClustering, DBSCAN, AgglomerativeClustering
)

results = []

def safe_silhouette(X2d, labels):
    # Silhouette —Ç—Ä–µ–±—É–µ—Ç >=2 –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –∏ —á—Ç–æ–±—ã –Ω–µ –≤—Å–µ —Ç–æ—á–∫–∏ –±—ã–ª–∏ –≤ –æ–¥–Ω–æ–º –∫–ª–∞—Å—Ç–µ—Ä–µ
    uniq = set(labels)
    if len(uniq) < 2:
        return np.nan
    try:
        return silhouette_score(X2d, labels)
    except Exception:
        return np.nan

def evaluate(name, labels):
    return {
        "Method": name,
        "FMI": fowlkes_mallows_score(y_true, labels),
        "Silhouette": safe_silhouette(X_2d, labels),
        "Clusters": len(set(labels))
    }
KMeans (Random) K=4
labels = KMeans(n_clusters=4, init="random", n_init=10, random_state=42).fit_predict(X_2d)
results.append(evaluate("KMeans (init=random)", labels))
KMeans++ K=4
labels = KMeans(n_clusters=4, init="k-means++", n_init=10, random_state=42).fit_predict(X_2d)
results.append(evaluate("KMeans (init=k-means++)", labels))
Bisecting KMeans (Random) K=4
labels = BisectingKMeans(n_clusters=4, init="random", random_state=42).fit_predict(X_2d)
results.append(evaluate("BisectingKMeans (init=random)", labels))
Spectral Clustering (default) K=4
labels = SpectralClustering(n_clusters=4, random_state=42).fit_predict(X_2d)
results.append(evaluate("SpectralClustering (default)", labels))
12) DBSCAN: –ø–æ–¥–æ–±—Ä–∞—Ç—å eps –∏ min_samples —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å 4 –∫–ª–∞—Å—Ç–µ—Ä–∞
–ó–∞–¥–∞–Ω–∏–µ –ø—Ä–æ—Å–∏—Ç: –∫–∞–∫–∏–µ eps –∏ min_samples —Ç—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å 4 clusters.

def dbscan_find_params(X2d, target_k=4):
    eps_grid = np.linspace(0.1, 5.0, 60)
    min_samples_grid = [3, 4, 5, 6, 8, 10]

    best = None  # (sil, eps, ms, labels, k)
    for ms in min_samples_grid:
        for eps in eps_grid:
            model = DBSCAN(eps=float(eps), min_samples=int(ms))
            labels = model.fit_predict(X2d)
            k = len(set(labels)) - (1 if -1 in labels else 0)  # without noise

            if k == target_k:
                # silhouette —Å—á–∏—Ç–∞–µ–º –Ω–∞ –≤—Å–µ—Ö —Ç–æ—á–∫–∞—Ö (–≤–∫–ª—é—á–∞—è noise) —á–∞—Å—Ç–æ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ,
                # –ø–æ—ç—Ç–æ–º—É —Å—á–∏—Ç–∞–µ–º –Ω–∞ non-noise, –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ
                mask = labels != -1
                if mask.sum() < 2 or len(set(labels[mask])) < 2:
                    sil = -np.inf
                else:
                    try:
                        sil = silhouette_score(X2d[mask], labels[mask])
                    except Exception:
                        sil = -np.inf

                cand = (sil, eps, ms, labels, k)
                if (best is None) or (cand[0] > best[0]):
                    best = cand
    return best

best_db = dbscan_find_params(X_2d, target_k=4)

if best_db is None:
    print("DBSCAN: –Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –¥–∞—é—â–∏–µ —Ä–æ–≤–Ω–æ 4 –∫–ª–∞—Å—Ç–µ—Ä–∞. –†–∞—Å—à–∏—Ä—é —Å–µ—Ç–∫—É ‚Äî —Å–∫–∞–∂–∏.")
else:
    sil, eps_used, ms_used, labels, k = best_db
    print(f"DBSCAN –Ω–∞–π–¥–µ–Ω–æ: eps={eps_used:.3f}, min_samples={ms_used}, clusters={k}")

    mask = labels != -1
    results.append({
        "Method": f"DBSCAN (eps={eps_used:.3f}, min_samples={ms_used})",
        "FMI": fowlkes_mallows_score(y_true[mask], labels[mask]),
        "Silhouette": safe_silhouette(X_2d[mask], labels[mask]),
        "Clusters": k
    })
13) Agglomerative (Hierarchical) K=4: single/complete/average/ward
for link in ["single", "complete", "average", "ward"]:
    labels = AgglomerativeClustering(n_clusters=4, linkage=link).fit_predict(X_2d)
    results.append(evaluate(f"Agglomerative (linkage={link})", labels))
14) –¢–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ + ranking
df = pd.DataFrame(results)

print("=== ALL RESULTS ===")
display(df)

print("=== Rank by FMI (best -> worst) ===")
display(df.sort_values("FMI", ascending=False).reset_index(drop=True))

print("=== Rank by Silhouette (best -> worst) ===")
display(df.sort_values("Silhouette", ascending=False).reset_index(drop=True))
–ß—Ç–æ —Ç–µ–±–µ –Ω—É–∂–Ω–æ –≤—Å—Ç–∞–≤–∏—Ç—å –≤ –æ—Ç—á—ë—Ç –ø—Ä–æ DBSCAN
–ü–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ –±–ª–æ–∫–∞ DBSCAN —É —Ç–µ–±—è –ø–æ—è–≤–∏—Ç—Å—è —Å—Ç—Ä–æ–∫–∞ –≤–∏–¥–∞:

DBSCAN –Ω–∞–π–¥–µ–Ω–æ: eps=..., min_samples=..., clusters=4

–≠—Ç–∏ eps –∏ min_samples ‚Äî —Ä–æ–≤–Ω–æ —Ç–æ, —á—Ç–æ —Ç—Ä–µ–±—É–µ—Ç –≤–æ–ø—Ä–æ—Å –∑–∞–¥–∞–Ω–∏—è.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å ‚Äî —Å–∫–∏–Ω—å —Å—é–¥–∞ —Å–∫—Ä–∏–Ω/–∑–Ω–∞—á–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã df (–∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —Ç–æ–ø-3 –º–µ—Ç–æ–¥–∞ –ø–æ FMI –∏ Silhouette), –∏ —è –Ω–∞–ø–∏—à—É —Ç–µ–±–µ –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç ‚ÄúResults & Discussion‚Äù –ø–æ–¥ —Å—Ç–∏–ª—å Dr. Ho.

–í—ã —Å–∫–∞–∑–∞–ª–∏:
Untitled9 (1).ipynb
–§–∞–π–ª
—á–µ–∫–Ω–∏ , –≤—Å–µ –ª–∏ —Ç–∞–∫ –≥–ª–∞–¥–∫–æ —Ä–æ–≤–Ω–æ —á—Ç–æ —Ç—Ä–µ–±–æ–≤–∞–ª–æ—Å—å?
ChatGPT —Å–∫–∞–∑–∞–ª:

–î—É–º–∞–ª –Ω–∞ –ø—Ä–æ—Ç—è–∂–µ–Ω–∏–∏ 43s
–î–∞, –ø–æ —Ç–≤–æ–µ–º—É –Ω–æ—É—Ç–±—É–∫—É –ø–æ—á—Ç–∏ –≤—Å—ë —Å–¥–µ–ª–∞–Ω–æ —Ä–æ–≤–Ω–æ —Ç–∞–∫, –∫–∞–∫ —Ç—Ä–µ–±—É–µ—Ç –∑–∞–¥–∞–Ω–∏–µ. –Ø –ø—Ä–æ–±–µ–∂–∞–ª—Å—è –ø–æ –∫–æ–¥—É –∏ —Å–≤–µ—Ä–∏–ª –ø–æ —á–µ–∫-–ª–∏—Å—Ç—É.

–ß—Ç–æ —É–∂–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º (‚úÖ)
‚úÖ Resize 224√ó224 –ø–µ—Ä–µ–¥ feature extraction.

‚úÖ Normalize (ImageNet mean/std).

‚úÖ ResNet18 pretrained –∏ —Ñ–∏—á–∏ –±–µ—Ä—É—Ç—Å—è –∏–∑ layer4 (–ø–æ—Å–ª–µ–¥–Ω–∏–π conv-–±–ª–æ–∫) + Global Average Pooling ‚Üí –≤–µ–∫—Ç–æ—Ä –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.

‚úÖ Dimension reduction –¥–æ 2D (—É —Ç–µ–±—è PCA –Ω–∞ 2 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã).

‚úÖ –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –Ω–∞ 2D –¥–∞—Ç–∞—Å–µ—Ç–µ –≤—Å–µ–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –∏–∑ –ø—É–Ω–∫—Ç–∞ 3:

‚úÖ KMeans init="random", K=4

‚úÖ KMeans init="k-means++", K=4

‚úÖ BisectingKMeans init="random", K=4

‚úÖ SpectralClustering

‚úÖ DBSCAN + –ø–æ–∏—Å–∫ eps/min_samples –¥–ª—è 4 –∫–ª–∞—Å—Ç–µ—Ä–æ–≤

‚úÖ AgglomerativeClustering linkage in ["single","complete","average","ward"] –∏ n_clusters=4

‚úÖ –ú–µ—Ç—Ä–∏–∫–∏:

‚úÖ Fowlkes‚ÄìMallows index –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–µ—Ç–æ–¥–∞

‚úÖ Silhouette –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–µ—Ç–æ–¥–∞ (—É —Ç–µ–±—è –µ—Å—Ç—å safe-–æ–±—Ä–∞–±–æ—Ç–∫–∞)

‚úÖ –ï—Å—Ç—å ranking (best‚Üíworst) –æ—Ç–¥–µ–ª—å–Ω–æ –ø–æ FMI –∏ –æ—Ç–¥–µ–ª—å–Ω–æ –ø–æ Silhouette.

–ß—Ç–æ –Ω—É–∂–Ω–æ –ø–æ–¥–ø—Ä–∞–≤–∏—Ç—å, —á—Ç–æ–±—ã –±—ã–ª–æ ¬´–∏–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥ —Ç–µ–∫—Å—Ç –∑–∞–¥–∞–Ω–∏—è¬ª (‚ö†Ô∏è, –º–µ–ª–æ—á–∏)
Reference –Ω–∞ kozodoi
–í –∑–∞–¥–∞–Ω–∏–∏ –ø—Ä—è–º–æ —Å–∫–∞–∑–∞–Ω–æ: ‚Äúmust reference this website in your solution‚Äù.
–î–æ–±–∞–≤—å Markdown —è—á–µ–π–∫—É (–∏–ª–∏ —Ç–µ–∫—Å—Ç –≤ –æ—Ç—á—ë—Ç) —Å–æ —Å—Å—ã–ª–∫–æ–π:

https://kozodoi.me/blog/20210527/extracting-features

SpectralClustering ‚Äúdefault parameters‚Äù
–¢—ã –¥–æ–±–∞–≤–∏–ª random_state=42. –≠—Ç–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ, –Ω–æ —Ñ–æ—Ä–º–∞–ª—å–Ω–æ —ç—Ç–æ —É–∂–µ –Ω–µ ‚Äúdefault‚Äù.
–ï—Å–ª–∏ —Ö–æ—á–µ—à—å 100% —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–µ ‚Äî —Å–¥–µ–ª–∞–π —Ç–∞–∫:

labels = SpectralClustering(n_clusters=4).fit_predict(X_2d)
(–∏–ª–∏ –æ—Å—Ç–∞–≤—å –∫–∞–∫ –µ—Å—Ç—å –∏ –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ ‚Äúwe set random_state for reproducibility‚Äù.)

DBSCAN –∏ –º–µ—Ç—Ä–∏–∫–∏
–¢—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∏—â–µ—à—å eps/min_samples –¥–ª—è 4 –∫–ª–∞—Å—Ç–µ—Ä–æ–≤.
–ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç: —É DBSCAN –±—ã–≤–∞–µ—Ç noise -1, –∏ —Ç—ã —Å—á–∏—Ç–∞–µ—à—å FMI/Silhouette –Ω–∞ mask != -1. –≠—Ç–æ –æ–∫, –Ω–æ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –Ω–∞–ø–∏—à–∏ 1 —Å—Ç—Ä–æ–∫—É –≤ –æ—Ç—á—ë—Ç–µ, —á—Ç–æ:

‚ÄúFor DBSCAN, metrics were computed on non-noise points only (labels != -1).‚Äù

–§–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ ‚Äúdog dataset‚Äù
–í –∑–∞–¥–∞–Ω–∏–∏ –µ—Å—Ç—å ‚Äúdog image dataset‚Äù, –Ω–æ —É —Ç–µ–±—è solar panel dataset. –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –Ω–æ –≤ –æ—Ç—á—ë—Ç–µ –¥–æ–±–∞–≤—å 1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ:

‚ÄúWe used the same Faulty_solar_panel dataset as in previous assignments, as required.‚Äù

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å ‚Äî –ø—Ä–∏—à–ª–∏ —Å—é–¥–∞ —Å–∫—Ä–∏–Ω —Ç–∞–±–ª–∏—Ü—ã df (–∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —Ç–æ–ø-3 –ø–æ FMI –∏ Silhouette), –∏ —è —Å–∫–∞–∂—É, –≤—ã–≥–ª—è–¥–∏—Ç –ª–∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ ‚Äú–∞–¥–µ–∫–≤–∞—Ç–Ω–æ‚Äù (—Ç–æ–∂–µ —á–∞—Å—Ç—ã–π –≤–æ–ø—Ä–æ—Å —É Dr. Ho).

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–¥–∞–≤–∞–π –¥–æ–ø–æ–ª–æ–Ω–∏ —á—Ç–æ –Ω—É–∂–Ω–æ –¥–æ–ø–æ–ª–Ω–∏—Ç—å –∏ —Å–∫–∏–Ω—å –º–Ω–µ –æ–±—Ä–∞—Ç–Ω–æ
ChatGPT —Å–∫–∞–∑–∞–ª:

–î—É–º–∞–ª –Ω–∞ –ø—Ä–æ—Ç—è–∂–µ–Ω–∏–∏ 1m 9s
–ì–æ—Ç–æ–≤–æ ‚Äî —è –¥–æ–ø–æ–ª–Ω–∏–ª –Ω–æ—É—Ç–±—É–∫ —Ä–æ–≤–Ω–æ —Ç–µ–º, —á–µ–≥–æ –Ω–µ —Ö–≤–∞—Ç–∞–ª–æ –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º, –∏ –∏—Å–ø—Ä–∞–≤–∏–ª SpectralClustering –ø–æ–¥ ‚Äúdefault parameters‚Äù.

–ß—Ç–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ/–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –≤–Ω—É—Ç—Ä–∏ –Ω–æ—É—Ç–±—É–∫–∞:

‚úÖ Markdown-–±–ª–æ–∫: —á—Ç–æ —Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ—à—å —Ç–æ—Ç –∂–µ –¥–∞—Ç–∞—Å–µ—Ç Faulty_solar_panel (–∏ –ø–æ—á–µ–º—É ‚Äúdog dataset‚Äù –≤ —Ç–µ–∫—Å—Ç–µ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ).

‚úÖ Markdown-–±–ª–æ–∫ —Å –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–π —Å—Å—ã–ª–∫–æ–π-—Ä–µ—Ñ–µ—Ä–µ–Ω—Å–æ–º –Ω–∞ kozodoi (–∫–∞–∫ —Ç—Ä–µ–±—É–µ—Ç Dr. Ho).

‚úÖ Markdown-–±–ª–æ–∫ –ø—Ä–æ DBSCAN: –ø–æ–¥–±–æ—Ä eps/min_samples –Ω–∞ 4 –∫–ª–∞—Å—Ç–µ—Ä–∞ + –∫–∞–∫ —Å—á–∏—Ç–∞—é—Ç—Å—è –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ noise -1.

‚úÖ SpectralClustering —Ç–µ–ø–µ—Ä—å —Ä–µ–∞–ª—å–Ω–æ —Å default params (random_state —É–±—Ä–∞–ª), –∏ –ø–æ–¥–ø–∏—Å—å –º–µ—Ç–æ–¥–∞ —Ç–æ–∂–µ –ø–æ–ø—Ä–∞–≤–∏–ª.

–í–æ—Ç —Ñ–∞–π–ª –æ–±—Ä–∞—Ç–Ω–æ: Download the updated notebook

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
—á—Ç–æ –æ–Ω –∏–º–µ–µ—Ç –≤–≤–∏–¥—É?
ChatGPT —Å–∫–∞–∑–∞–ª:
–ö–æ—Ä–æ—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É üëá
–≠—Ç–æ –Ω–µ –æ—à–∏–±–∫–∞ –≤ —Ç–≤–æ—ë–º –∫–æ–¥–µ –∏ –Ω–µ –ø—Ä–æ–±–ª–µ–º–∞ –¥–ª—è –∑–∞–¥–∞–Ω–∏—è.

–ß—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ
WARNING: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.

–≠—Ç–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ (Colab / Jupyter), –∞ –Ω–µ –æ—Ç Python –∏–ª–∏ sklearn.

–ß–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–º —è–∑—ã–∫–æ–º:
–¢–∞–±–ª–∏—Ü–∞ df –±—ã–ª–∞ —Å–æ–∑–¥–∞–Ω–∞ —Ä–∞–Ω—å—à–µ

–ü–æ—Ç–æ–º:

—Ç—ã –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏–ª —è–¥—Ä–æ, –∏–ª–∏

–∏–∑–º–µ–Ω–∏–ª/–ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏–ª —è—á–µ–π–∫–∏ –≤—ã—à–µ, –∏–ª–∏

df –±—ã–ª –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞–Ω

UI –ø—ã—Ç–∞–µ—Ç—Å—è –∑–∞–Ω–æ–≤–æ –æ—Ç—Ä–∏—Å–æ–≤–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏/—Ç–∞–±–ª–∏—Ü—ã,
–Ω–æ –≤ –ø–∞–º—è—Ç–∏ —É–∂–µ –Ω–µ—Ç —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ç–æ—Ç —Å–∞–º—ã–π df

üëâ –ü–æ—ç—Ç–æ–º—É –æ–Ω –∏ –≥–æ–≤–æ—Ä–∏—Ç: ¬´—è –±–æ–ª—å—à–µ –Ω–µ –∑–Ω–∞—é, —á—Ç–æ —ç—Ç–æ –∑–∞ dataframe¬ª.

–í–∞–∂–Ω–æ: —ç—Ç–æ –ù–ï –∑–Ω–∞—á–∏—Ç, —á—Ç–æ
‚ùå –∫–æ–¥ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π
‚ùå —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ–≤–µ—Ä–Ω—ã–µ
‚ùå –∑–∞–¥–∞–Ω–∏–µ —Å–¥–µ–ª–∞–Ω–æ –ø–ª–æ—Ö–æ

–ê–ª–≥–æ—Ä–∏—Ç–º—ã, –º–µ—Ç—Ä–∏–∫–∏, —Ä–∞—Å—á—ë—Ç—ã ‚Äî –≤—Å—ë —É–∂–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.

–ö–∞–∫ —ç—Ç–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å (2 —Å–µ–∫—É–Ω–¥—ã)
–ü—Ä–æ—Å—Ç–æ —Å–¥–µ–ª–∞–π –æ–¥–Ω–æ –∏–∑ –¥–≤—É—Ö:

‚úÖ –í–∞—Ä–∏–∞–Ω—Ç 1 (—Å–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π)
üîÅ –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏ —è—á–µ–π–∫—É, –≥–¥–µ —Å–æ–∑–¥–∞—ë—Ç—Å—è df –∏ —Å—Ç—Ä–æ—è—Ç—Å—è –≥—Ä–∞—Ñ–∏–∫–∏:

df = pd.DataFrame(results)
display(df)
‚úÖ –í–∞—Ä–∏–∞–Ω—Ç 2 (–µ—Å–ª–∏ —Ö–æ—á–µ—à—å –∏–¥–µ–∞–ª—å–Ω–æ)
–ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏ Runtime ‚Üí Restart and run all
(–Ω–æ —ç—Ç–æ —É–∂–µ –∏–∑–±—ã—Ç–æ—á–Ω–æ)

–ù—É–∂–Ω–æ –ª–∏ —ç—Ç–æ –∏—Å–ø—Ä–∞–≤–ª—è—Ç—å –¥–ª—è —Å–¥–∞—á–∏?
–ù–µ—Ç.
–ï—Å–ª–∏ —Ç—ã:

—Å–¥–∞—ë—à—å .ipynb

–∏–ª–∏ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—à—å –≤ PDF
‚Äî –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å –≤–æ–æ–±—â–µ –Ω–µ —É–≤–∏–¥–∏—Ç —ç—Ç–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ.

–ò—Ç–æ–≥ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π
üëâ –≠—Ç–æ UI-–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ, –∞ –Ω–µ –æ—à–∏–±–∫–∞ –≤ –∑–∞–¥–∞–Ω–∏–∏.
üëâ –ù–∞ –æ—Ü–µ–Ω–∫—É –Ω–µ –≤–ª–∏—è–µ—Ç.
üëâ –ü—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏ —è—á–µ–π–∫—É ‚Äî –∏ –≤—Å—ë.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –º–æ–∂–µ—à—å —Å–∫–∏–Ω—É—Ç—å —Å–∫—Ä–∏–Ω —Å–∞–º–æ–π —Ç–∞–±–ª–∏—Ü—ã df, —è —Å–∫–∞–∂—É, –≤—ã–≥–ª—è–¥–∏—Ç –ª–∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–æ–≥–∏—á–Ω–æ —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è Dr. Ho.

–í—ã —Å–∫–∞–∑–∞–ª–∏:
4. (Clustering Evaluations) For all the methods in Item 3:
(a) Perform clustering performance evaluation using Fowlkes-Mallows index (sklearn.metrics.fowlkes
mallows score). Compute the Fowlkes-Mallows index for each method on the 2D dataset. (0.5
point)
(b) Perform clustering performance evaluation using Silhouette Coefficient (sklearn.metrics.silhouette score).
Compute the Silhouette Coefficient for each method. (0.5 point)
(c) Rank the methods from the best to the worst for your dataset based on Fowlkes-Mallows index.
(0.5 point)
(d) Rank the methods from the best to the worst for your dataset based on Silhouette Coefficient.
(0.5 point)
2

–º—ã —ç—Ç–æ –≤—ã–ø–æ–ª–Ω–∏–ª–∏?
ChatGPT —Å–∫–∞–∑–∞–ª:
–î–∞ ‚Äî –º—ã —ç—Ç–æ –≤—ã–ø–æ–ª–Ω–∏–ª–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ. –ù–∏–∂–µ ‚Äî —á–µ–∫-–ª–∏—Å—Ç —Å—Ç—Ä–æ–≥–æ –ø–æ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–µ –∑–∞–¥–∞–Ω–∏—è, –±–µ–∑ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–π.

4(a) Fowlkes‚ÄìMallows index ‚Äî –í–´–ü–û–õ–ù–ï–ù–û ‚úÖ
–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ:

Compute the Fowlkes‚ÄìMallows index for each method on the 2D dataset

–ß—Ç–æ —É —Ç–µ–±—è —Å–¥–µ–ª–∞–Ω–æ:

–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –Ω–∞ X_2d (–ø–æ—Å–ª–µ PCA)

–î–ª—è –∫–∞–∂–¥–æ–≥–æ –º–µ—Ç–æ–¥–∞ –∏–∑ Item 3 —Å—á–∏—Ç–∞–µ—Ç—Å—è:

fowlkes_mallows_score(y_true, labels)
–ú–µ—Ç–æ–¥—ã, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö FMI –ø–æ—Å—á–∏—Ç–∞–Ω:

KMeans (init=random)

KMeans (init=k-means++)

Bisecting KMeans

Spectral Clustering

DBSCAN (–Ω–∞ non-noise —Ç–æ—á–∫–∞—Ö ‚Äî —ç—Ç–æ –¥–æ–ø—É—Å—Ç–∏–º–æ, —Å–º. –ø—Ä–∏–º–µ—á–∞–Ω–∏–µ –Ω–∏–∂–µ)

Agglomerative (single)

Agglomerative (complete)

Agglomerative (average)

Agglomerative (ward)

‚û° –¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ 4(a) –∑–∞–∫—Ä—ã—Ç–æ –Ω–∞ 100%.

4(b) Silhouette Coefficient ‚Äî –í–´–ü–û–õ–ù–ï–ù–û ‚úÖ
–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ:

Compute the Silhouette Coefficient for each method

–ß—Ç–æ —Å–¥–µ–ª–∞–Ω–æ:

Silhouette —Å—á–∏—Ç–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑:

silhouette_score(X_2d, labels)
–î–æ–±–∞–≤–ª–µ–Ω–∞ safe-–ø—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ–±—ã:

–Ω–µ –ø–∞–¥–∞—Ç—å, –µ—Å–ª–∏ –æ–¥–∏–Ω –∫–ª–∞—Å—Ç–µ—Ä

–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å DBSCAN

‚û° –ú–µ—Ç—Ä–∏–∫–∞ —Å—á–∏—Ç–∞–µ—Ç—Å—è –¥–ª—è –≤—Å–µ—Ö –º–µ—Ç–æ–¥–æ–≤, –≥–¥–µ —ç—Ç–æ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–æ–ø—É—Å—Ç–∏–º–æ.

4(c) Ranking –ø–æ Fowlkes‚ÄìMallows (best ‚Üí worst) ‚Äî –í–´–ü–û–õ–ù–ï–ù–û ‚úÖ
–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ:

Rank the methods from the best to the worst based on FMI

–ß—Ç–æ —É —Ç–µ–±—è –µ—Å—Ç—å:

df.sort_values("FMI", ascending=False)
–≠—Ç–æ:

—è–≤–Ω—ã–π ranking

–æ—Ç –ª—É—á—à–µ–≥–æ –∫ —Ö—É–¥—à–µ–º—É

–ø–æ –æ–¥–Ω–æ–π –º–µ—Ç—Ä–∏–∫–µ (FMI)

‚û° –¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ —Å—Ç—Ä–æ–≥–æ –ø–æ —Ç–µ–∫—Å—Ç—É.

4(d) Ranking –ø–æ Silhouette (best ‚Üí worst) ‚Äî –í–´–ü–û–õ–ù–ï–ù–û ‚úÖ
–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ:

Rank the methods from the best to the worst based on Silhouette Coefficient

–ß—Ç–æ —É —Ç–µ–±—è –µ—Å—Ç—å:

df.sort_values("Silhouette", ascending=False)
–≠—Ç–æ:

–æ—Ç–¥–µ–ª—å–Ω—ã–π ranking

–Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–π –æ—Ç FMI

–Ω–∞ —Ç–æ–º –∂–µ 2D –¥–∞—Ç–∞—Å–µ—Ç–µ

‚û° –¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é.

–í–∞–∂–Ω–æ–µ —É—Ç–æ—á–Ω–µ–Ω–∏–µ –ø—Ä–æ DBSCAN (—á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –ø—Ä–∏–¥–∏—Ä–æ–∫)
–¢—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ:

—É–±—Ä–∞–ª noise (label = -1)

–ø–æ—Å—á–∏—Ç–∞–ª –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ non-noise —Ç–æ—á–∫–∞—Ö

–≠—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞, –∏ –≤ –æ—Ç—á—ë—Ç–µ —É —Ç–µ–±—è –µ—Å—Ç—å –ø–æ—è—Å–Ω–µ–Ω–∏–µ.

–§–∏–Ω–∞–ª—å–Ω—ã–π –≤–µ—Ä–¥–∏–∫—Ç
–ü—É–Ω–∫—Ç	–°—Ç–∞—Ç—É—Å
4(a) FMI –¥–ª—è –≤—Å–µ—Ö –º–µ—Ç–æ–¥–æ–≤	‚úÖ
4(b) Silhouette –¥–ª—è –≤—Å–µ—Ö –º–µ—Ç–æ–¥–æ–≤	‚úÖ
4(c) Ranking –ø–æ FMI	‚úÖ
4(d) Ranking –ø–æ Silhouette	‚úÖ
üëâ –í—Å–µ –ø—É–Ω–∫—Ç—ã 4(a)‚Äì4(d) –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —Ä–æ–≤–Ω–æ —Ç–∞–∫, –∫–∞–∫ —Ç—Ä–µ–±—É–µ—Ç –∑–∞–¥–∞–Ω–∏–µ.
–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, —Å–ª–µ–¥—É—é—â–∏–º —à–∞–≥–æ–º —è –º–æ–≥—É:

–ø–æ–º–æ—á—å —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å 1 –∞–±–∑–∞—Ü ‚ÄúResults & Discussion‚Äù,

–∏–ª–∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω–µ –≤—ã–≥–ª—è–¥–∏—Ç –ª–∏ ranking ‚Äú–ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ‚Äù —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è (—ç—Ç–æ –∏–Ω–æ–≥–¥–∞ –≤–∞–∂–Ω–æ).

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–Ω–µ –Ω—É–∂–Ω–æ –ø–∏—Å–∞—Ç—å —Ç–µ–∫—Å—Ç –∏–ª–∏ –µ—â–µ —á—Ç–æ—Ç–æ?
ChatGPT —Å–∫–∞–∑–∞–ª:
–ö–æ—Ä–æ—Ç–∫–∏–π –∏ —á–µ—Å—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç: –ø–æ –∑–∞–¥–∞–Ω–∏—é ‚Äî –Ω–µ—Ç, –±–æ–ª—å—à–µ –Ω–∏—á–µ–≥–æ –ø–∏—Å–∞—Ç—å –ù–ï –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ.
–ù–æ –µ—Å—Ç—å –º–∏–Ω–∏–º—É–º, –∫–æ—Ç–æ—Ä—ã–π —è —Ä–µ–∫–æ–º–µ–Ω–¥—É—é, —á—Ç–æ–±—ã –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å –Ω–µ –∏—Å–∫–∞–ª, –∫ —á–µ–º—É –ø—Ä–∏–¥—Ä–∞—Ç—å—Å—è.

–ß—Ç–æ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ø–æ –∑–∞–¥–∞–Ω–∏—é
–ï—Å–ª–∏ –≤ Canvas/–æ–ø–∏—Å–∞–Ω–∏–∏ –Ω–µ –Ω–∞–ø–∏—Å–∞–Ω–æ ‚Äúwrite a report‚Äù / ‚Äúdiscussion‚Äù, —Ç–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ:

‚úÖ –∫–æ–¥
‚úÖ –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
‚úÖ —Ç–∞–±–ª–∏—Ü—ã —Å FMI –∏ Silhouette
‚úÖ ranking (best ‚Üí worst)

üëâ –£ —Ç–µ–±—è —ç—Ç–æ —É–∂–µ –µ—Å—Ç—å.

–ß—Ç–æ –ñ–ï–õ–ê–¢–ï–õ–¨–ù–û (–Ω–æ 3‚Äì4 —Å—Ç—Ä–æ–∫–∏, –Ω–µ ‚Äú—ç—Å—Å–µ‚Äù)
–Ø —Å–æ–≤–µ—Ç—É—é –¥–æ–±–∞–≤–∏—Ç—å –û–î–ù–£ –∫–æ—Ä–æ—Ç–∫—É—é Markdown-—è—á–µ–π–∫—É –ø–µ—Ä–µ–¥ –≤—ã–≤–æ–¥–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. –≠—Ç–æ –∑–∞–Ω–∏–º–∞–µ—Ç 30 —Å–µ–∫—É–Ω–¥, –Ω–æ —Å–∏–ª—å–Ω–æ —Å–Ω–∏–∂–∞–µ—Ç —Ä–∏—Å–∫ –≤–æ–ø—Ä–æ—Å–æ–≤.

–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π safe-—Ç–µ–∫—Å—Ç (–º–æ–∂–Ω–æ copy-paste)
### Clustering Evaluation

All clustering methods were evaluated on the 2D representation of the dataset using
the Fowlkes‚ÄìMallows Index (external evaluation with ground truth labels) and the
Silhouette Coefficient (internal evaluation). The methods were ranked from best to
worst separately based on each metric.
–ü—Ä–æ DBSCAN (–æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞, –µ—Å–ª–∏ —Ö–æ—á–µ—à—å –∏–¥–µ–∞–ª—å–Ω–æ)
For DBSCAN, evaluation metrics were computed on non-noise samples only (labels ‚â† ‚àí1).
–ö–æ–≥–¥–∞ —Ç–µ–∫—Å—Ç –ù–ï –Ω—É–∂–µ–Ω –≤–æ–æ–±—â–µ
–ú–æ–∂–Ω–æ –Ω–∏—á–µ–≥–æ –Ω–µ –¥–æ–±–∞–≤–ª—è—Ç—å, –µ—Å–ª–∏:

—Å–¥–∞—ë—à—å .ipynb

–ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å –æ–±—ã—á–Ω–æ —Å–º–æ—Ç—Ä–∏—Ç –∫–æ–¥

–≤ –ø—Ä–æ—à–ª—ã—Ö –∑–∞–¥–∞–Ω–∏—è—Ö —Ç–µ–∫—Å—Ç –Ω–µ —Ç—Ä–µ–±–æ–≤–∞–ª–∏

–¢–æ–≥–¥–∞ —Ç—ã —É–∂–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—à—å –∑–∞–¥–∞–Ω–∏—é.

–ú–æ–π —á–µ—Å—Ç–Ω—ã–π —Å–æ–≤–µ—Ç
üü¢ –ï—Å–ª–∏ —Ö–æ—á–µ—à—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ ‚Üí –¥–æ–±–∞–≤—å 2 Markdown-—è—á–µ–π–∫–∏ (–≤—ã—à–µ).
üü¢ –ï—Å–ª–∏ —Ö–æ—á–µ—à—å –º–∏–Ω–∏–º—É–º –¥–µ–π—Å—Ç–≤–∏–π ‚Üí —Å–¥–∞–≤–∞–π –∫–∞–∫ –µ—Å—Ç—å, —ç—Ç–æ –Ω–µ –æ—à–∏–±–∫–∞.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, —è –º–æ–≥—É –ø—Ä–æ–≤–µ—Ä–∏—Ç—å Canvas instructions 1:1 –∏ —Å–∫–∞–∑–∞—Ç—å, —Ç—Ä–µ–±—É—é—Ç –ª–∏ –æ–Ω–∏ —Ç–µ–∫—Å—Ç –∏–º–µ–Ω–Ω–æ —É Dr. Ho (–æ–±—ã—á–Ω–æ ‚Äî –Ω–µ—Ç).

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–∫–æ—Ä–æ—á–µ –º—ã –≤—Å–µ –≤—ã–ø–æ–ª–Ω–∏–ª–∏ –¥–∞?
ChatGPT —Å–∫–∞–∑–∞–ª:
–î–∞. –ú—ã –≤—Å—ë –≤—ã–ø–æ–ª–Ω–∏–ª–∏. –¢–æ—á–∫–∞. ‚úÖ

–ö–æ—Ä–æ—Ç–∫–æ –∏ –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤:

‚úÖ Feature extraction (ResNet18, last conv layer)

‚úÖ Dimension reduction –¥–æ 2D

‚úÖ –í—Å–µ –º–µ—Ç–æ–¥—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –∏–∑ Item 3

‚úÖ FMI –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–µ—Ç–æ–¥–∞

‚úÖ Silhouette –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–µ—Ç–æ–¥–∞

‚úÖ Ranking best ‚Üí worst –ø–æ FMI

‚úÖ Ranking best ‚Üí worst –ø–æ Silhouette

üëâ –í—Å–µ –ø—É–Ω–∫—Ç—ã –∑–∞–¥–∞–Ω–∏—è –∑–∞–∫—Ä—ã—Ç—ã —Ä–æ–≤–Ω–æ —Ç–∞–∫, –∫–∞–∫ –æ–Ω–∏ –Ω–∞–ø–∏—Å–∞–Ω—ã.

–ù–∏—á–µ–≥–æ –¥–æ–ø–∏—Å—ã–≤–∞—Ç—å –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –Ω–µ –Ω—É–∂–Ω–æ.
–ú–æ–∂–µ—à—å —Å–ø–æ–∫–æ–π–Ω–æ —Å–¥–∞–≤–∞—Ç—å.

–ï—Å–ª–∏ –±—É–¥–µ—Ç –≤–æ–ø—Ä–æ—Å –æ—Ç –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è ‚Äî —Ç—ã —É–∂–µ –≥–æ—Ç–æ–≤ –Ω–∞ –Ω–µ–≥–æ –æ—Ç–≤–µ—Ç–∏—Ç—å.

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–Ω–∞–ø–∏—à–∏ –¥–µ—Å–∫—Ä–∏–ø—à–Ω –∏ —Ä–∏–¥–º–∏ –¥–ª—è –≥–∏—Ç—Ö–∞–±–∞
ChatGPT —Å–∫–∞–∑–∞–ª:
–ì–æ—Ç–æ–≤–æ. –ù–∏–∂–µ ‚Äî –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–π, —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç—Å–∫–∏–π –≤–∞—Ä–∏–∞–Ω—Ç –±–µ–∑ ‚Äúchatgpt-—Å—Ç–∏–ª—è‚Äù, –∫–æ—Ç–æ—Ä—ã–π –∏–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥–æ–π–¥—ë—Ç –¥–ª—è GitHub –∏ Dr. Ho.

üìå GitHub Repository Description (–∫–æ—Ä–æ—Ç–∫–∏–π)
Clustering analysis of image data using CNN-based feature extraction (ResNet18) and classical clustering algorithms with FMI and Silhouette evaluation.

üìò README.md (–ø–æ–ª–Ω–∞—è –≤–µ—Ä—Å–∏—è)
# Clustering Analysis with CNN Feature Extraction

This repository contains the implementation for **Programming Assignment 4 (Clustering Analysis)**.
The project focuses on clustering image data using deep feature representations extracted from a
pretrained **ResNet18** convolutional neural network, followed by dimensionality reduction and
classical clustering algorithms.

---

## Dataset

The **Faulty Solar Panel** image dataset is used in this project. It consists of four classes:

- Bird-drop  
- Clean  
- Dusty  
- Snow-Covered  

The same dataset was used in previous assignments, as required by the assignment instructions.
Ground-truth labels are used **only for external evaluation** and are **not used during clustering**.

---

## Feature Extraction

- Images are resized to **224 √ó 224** pixels.
- Image normalization is performed using **ImageNet mean and standard deviation**.
- A pretrained **ResNet18** model is used.
- Features are extracted from the **last convolutional layer (layer4)**.
- Global Average Pooling is applied to obtain a **512-dimensional feature vector** per image.

Feature extraction follows the approach described in:
> https://kozodoi.me/blog/20210527/extracting-features

---

## Dimensionality Reduction

- The extracted feature vectors are standardized.
- **Principal Component Analysis (PCA)** is applied to reduce the dimensionality to **2D**.

---

## Clustering Methods

Clustering is performed on the 2D representation using the following algorithms:

- K-Means (init = random, K = 4)
- K-Means++ (K = 4)
- Bisecting K-Means (init = random, K = 4)
- Spectral Clustering (default parameters, K = 4)
- DBSCAN (parameters selected to obtain 4 clusters)
- Agglomerative (Hierarchical) Clustering:
  - Single linkage
  - Complete linkage
  - Average linkage
  - Ward‚Äôs method

All clustering implementations use **scikit-learn**.

---

## Evaluation Metrics

Each clustering method is evaluated using:

- **Fowlkes‚ÄìMallows Index (FMI)**  
  External evaluation using ground-truth labels.

- **Silhouette Coefficient**  
  Internal evaluation based on cluster cohesion and separation.

For DBSCAN, evaluation metrics are computed on **non-noise samples only** (labels ‚â† ‚àí1).

---

## Results

- FMI and Silhouette scores are computed for **all clustering methods**.
- Clustering methods are ranked from **best to worst** separately based on:
  - Fowlkes‚ÄìMallows Index
  - Silhouette Coefficient

---

## Requirements

- Python 3.9+
- PyTorch
- torchvision
- scikit-learn
- numpy
- pandas

---

## Notes

This project is implemented strictly according to the assignment requirements and focuses on
methodology, evaluation, and comparison of clustering techniques rather than supervised learning.
‚úÖ –ò—Ç–æ–≥
‚úî –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ

‚úî –£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç—Å–∫–∏–π —Å—Ç–∏–ª—å

‚úî –ë–µ–∑ –ª–∏—à–Ω–µ–π –≤–æ–¥—ã

‚úî –ü–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∑–∞–¥–∞–Ω–∏—é

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å ‚Äî –º–æ–≥—É:

—É–∫–æ—Ä–æ—Ç–∏—Ç—å README –ø–æ–¥ very minimal GitHub style

–∏–ª–∏ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –ø–æ–¥ –ø—É–±–ª–∏—á–Ω–æ–µ –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ, –∞ –Ω–µ —É—á–µ–±–Ω—É—é —Ä–∞–±–æ—Ç—É




No file chosenNo file chosen
ChatGPT –º–æ–∂–µ—Ç –¥–æ–ø—É—Å–∫–∞—Ç—å –æ—à–∏–±–∫–∏. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –ø—Ä–æ–≤–µ—Ä—è—Ç—å –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
